---
title: "Produção de Amônia"
author: "Fernado Bispo, Jeff Caponero"
format:
    pdf:
      toc: true
      toc-title: Sumário
      colorlinks: true
      documentclass: report
      papersize: letter
      number-sections: false
      geometry:
        - top=30mm
        - left=30mm
        - right=20mm
        - bottom=20mm
        - heightrounded
      fig-pos: "H"
      fig-align: center
      lang: pt-BR
      # fontfamily: libertinus
      fontsize: 12pt
      include-in-header:
      - text: |
          \usepackage{caption}
          \usepackage{fontspec}
          \usepackage{xcolor}
          \usepackage{indentfirst}
          \captionsetup[table]{name=Tabela}
---

```{r pacotes}
#| echo: false
#| warning: false


# PACOTES ----

if (!require(pacman)) install.packages("pacman")

pacman::p_load(tidyverse,  janitor, stargazer,  sjmisc, summarytools,
               kableExtra, moments, ggpubr, formattable, gridExtra, 
               glue, corrplot, sessioninfo, readxl, writexl, ggthemes,
               patchwork,  plotly, lmtest, olsrr, gglm, ggplot2, rigr,
               tidymodels, GGally, skimr, performance, gtsummary)



summarytools::st_options(lang = "pt")
options(OutDec=",") 

``` 


```{r dados1}
#| echo: false
#| warning: false

## Dados 1 - Import ----

dados <- stackloss

### Arrumação ----
dados <- dados|>
  janitor::clean_names()

# Transformando as variaveis e mudando as unidades de medida.
dados1 <- dados|>
  mutate(
    acid_conc = acid_conc/10+50,
    stack_loss = stack_loss/10,
  )
```


# Introdução

Com base nos dados disponibilizados no *dataset* "stackloss" (do R base), que apresenta dados de 21 dias de operação de um indústria que realiza oxidação de amônia ($NH_3$) em ácido nítrico ($HNO_3$). O ácido nítrico produzido é absorvido na torre de absorção contracorrente. As informações disponíveis na base de dados referem-se a: 

-**Air fow**: que representa a taxa de operação da indústria (corrente de ar refrigerado);  
-**Water Temp**: é a temperatura de resfriamento da água que circula nos canos da torre de absorção;  
-**Acid.Conc.**: é a concentração do ácido [em porcentagem, após tratamento]; e  
-**stack.loss** (variável dependente) é o percentual (após tratamento) de amônia introduzida no processo industrial que escapa da absorção (representando uma medida(inversa) de eficiência total da indústria).  


Com base nestes dados, objetiva-se:


1. Ajustar um modelo linear múltiplo completo para estes dados. Avaliando as estimativas dos parâmetros, os resíduos e a influência das observações no ajuste do modelo, incluindo leverage, distância de Cook, DFBETAs, DFFITs e COVRATIOs.  

2. Avaliar a partir de regressão parcial e dos resíduos parciais as variáveis no modelo, bem como o pressuposto de normalidade do resíduos.

# Resultados

## Análise descritiva dos dados




```{r tab1:MedRes}
#| echo: false
#| warning: false

dados1|>
  rename(
    "Fluxo de Ar" = air_flow,
    "Temperatura da Água" = water_temp,
    "Concentração de HNO3" = acid_conc,
    "Amônia Perdida" = stack_loss
  )|>
  summarytools::descr(
    stats = c("min", "q1", "med", "mean","q3", "max",  "sd", "cv", "Skewness", "Kurtosis"),
    justify = "c",
    style = "rmarkdown",
    transpose = T
  )|>
  kbl(
    caption = "Medidas Resumo dos dados",
    digits = 2,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", 
    row.names = T, 
    booktabs = T
  )|>
  column_spec(1, bold = T)|>
  kable_styling(
    full_width = F,
    position = 'center', 
    latex_options = c("striped", "HOLD_position", "scale_down")
  )|>
  kable_material()
```



```{r fig3:BoxPlot2}
#| echo: false
#| warning: false
#| fig-height: 6
#| fig-width: 6

# BoxPlot ----
{
## b1 volume de ar----
b1 <- dados1|>
  ggplot(aes(y = air_flow)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Fluxo de Ar",
    x = "",
    y = "m³"
  )+theme_minimal(base_size = 7.5)

## b2 Temperatura da água ----
b2 <- dados1|>
  ggplot(aes(y = water_temp)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Temperatura da Água",
    x = "",
    y = "ºC"
  )+theme_minimal(base_size = 7.5)

## b3 Concentração de HNO_3 ----
b3 <- dados1|>
  ggplot(aes(y = acid_conc)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Concentração de HNO3",
    x = "",
    y = "g/L"
  )+theme_minimal(base_size = 7.5)

## b4 Perda ----
b4 <- dados1|>
  ggplot(aes(y = stack_loss)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Amônia Perdida",
    x = "",
    y = "Porcentagem"
  )+theme_minimal(base_size = 7.5)

b1 + b2 + b3 + b4 + 
  plot_layout(ncol = 2) + 
  plot_annotation(
    title = "Figura 1: BoxPlot das variáveis em análise.",
    tag_levels = c("A", "2"))&
   theme(
     legend.position = "none",
     plot.tag.position = c(1, 0),
     plot.tag = element_text(size = 12, hjust = 1, vjust = -2.2)
   )
}

```




## Modelo de Regressão Linear Multipla  

O modelo obtido pode ser representado por:

```{r }
#| echo: false
#| warning: false

n <- length(dados1$stack_loss)
Y <- as.matrix(dados1$stack_loss)
X <- as.matrix(dados1[,-4])
X <- cbind(1,X)
betas <- (solve(t(X) %*% X)) %*% t(X) %*% Y
H = X %*% (solve(t(X) %*% X)) %*% t(X)
J <- matrix(1,n,n)
SQRes <- t(Y) %*% Y - t(betas) %*% t(X) %*% Y
SQReg <- t(betas) %*% t(X) %*% Y - (1/n)*t(Y) %*% J %*% Y
SQTot <- SQReg + SQRes

R2 <- round(SQReg/SQTot,3)
R2_aju <- round(1 - (SQRes/(n - 12))/(SQTot/(n -1)),3)
```


$Y_{i}=$`r round(betas[1],3)` $+$ `r round(betas[2],3)` $X_{1i} +$ `r round(betas[3],3)` $X_{2i}$ `r round(betas[4],3)` $X_{3i}$ 

Onde:    
$Y_{i}$ - Amônia Perdida;  
$X_{1i}$ - Fluxo de Ar;  
$X_{2i}$ - Temperatura da Água;  
$X_{3i}$ - Concentração de HNO3;  

Interpretando-se o modelo pode-se dizer que para cada variável, fixadas as demais condições (_Ceteris Paribus_), temos que a porcentagem de amônia perdida é de 3,614% caso todas as demais varíáveis tenham valor zero. Há um aumento de 0,072% na perda de amônia para cada metro cúbico de ar introduzido. O aumento de cada grau Ceusius da temperatura da água provoca uma aumento de 0,13% de aumento na perda de amônia. O aumento em 1g/L na concentração do ácido nítrico reduz em 0,152% a perda de amônia. Neste modelo o coeficiente de determinação calculado foi de $R^2=$ `r R2`, o que denota que `r R2*100`% da variância dos dados é explicada pelo modelo. Pode-se calcular o coeficiente de determinação ajustado igual a $R^2_a=$ `r R2_aju`.  

### Significância do Modelo

Após o ajuste do modelo existe a necessidade de se avaliar a significância do mesmo, o teste de hipótese para tal situação será realizado, contendo as seguintes hipóteses:

$$H_0: \hat{\beta_1} = 0$$
$$H_1: \hat{\beta_1} \neq 0.$$
As Tabelas 2 e 3 trazem os principais resultados da tabela ANOVA e do Intervalo de Confiança para os parâmetros, possibilitando assim inferir sobre o modelo ajustado.


```{r teste_diag_trans}
#| echo: false
#| warning: false

## Modelo Ajustado
mFit1 <- lm(stack_loss ~ air_flow + water_temp + acid_conc, data = dados1)

fit_anova <- anova(mFit1)|>
  as.data.frame()

fit_anova <- fit_anova|>
  mutate(
    `F value` = 
      scales::number(`F value`, accuracy = 0.0001, 
                     big.mark = ".", decimal.mark = ","),
    `Pr(>F)` = 
      scales::number(`Pr(>F)`, accuracy = 0.0001, 
                     big.mark = ".", decimal.mark = ","))

fit_anova[is.na(fit_anova)] <- ""

rownames(fit_anova) <- c( "Fluxo de Ar", "Temperatura da Água", 
                          "Concentração de HNO3", "Resíduos")

fit_anova|>
  kbl(
    caption = "Análise de Variância (ANOVA)",
    format.args=list(big.mark=".", decimal.mark=","),
    digits = 3, align = "c", row.names = T, 
    booktabs = T, escape = F,
    col.names = c("$GL^1$", "Soma de Quadrados", "Quadrado Médio", "Estatística F-Snedecor", "p-valor")
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header")
  )|>
  column_spec(1, bold = T
  )|>
    footnote(
    number = c("GL: Graus de Liberdade"),
    number_title = "Legenda:",
    footnote_as_chunk = F
  )|>
  kable_material()


resultados <- cbind(confint(mFit1))
rownames(resultados) <- c("$\\hat \\beta_0$", "$\\hat \\beta_1$", "$\\hat \\beta_2$", "$\\hat \\beta_3$")

resultados|>
  kbl(
    caption = "Intervalos de Confiança para os parâmetros estimados no MRLS.",
    format.args=list(big.mark=".", decimal.mark=","),
    digits = 3, align = "c", row.names = T, booktabs = T,
    escape = F,
    col.names = c("$LI^1$", "$LS^2$")
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header")
  )|>
  column_spec(1, bold = T
  )|>
    footnote(
    symbol = "Nível de Significância de 5%.",
    symbol_title = "",
    footnote_as_chunk = T
  )|>
    footnote(
    number = c(
      "LI: Limite Inferior (2,5%)", 
      "LS: Limite Superior (97,5%)"),
    number_title = "Legenda:",
    footnote_as_chunk = F
  )|>
  kable_material()
```

Com base na Tabela 2, avaliando o p-valor é possível afirmar que o modelo é significante rejeitando assim $H_0$ que tem como pressuposto $\hat{\beta_1} = \hat{\beta_2}=\hat{\beta_3}= 0$.

Através dos Intervalos de Confiança calculados (Tabela 4) é possível afirmar com 95% de confiança que o verdadeiro valor de $\beta_0$ está entre `r glue::glue('({scales::number(confint(mFit1)[1,1], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")}; {scales::number(confint(mFit1)[1,2], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")})')`; que o verdadeiro valor de $\beta_1$ está entre `r glue::glue('({scales::number(confint(mFit1)[2,1], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")}; {scales::number(confint(mFit1)[2,2], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")})')`; que o verdadeiro valor de $\beta_2$ está entre `r glue::glue('({scales::number(confint(mFit1)[3,1], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")}; {scales::number(confint(mFit1)[3,2], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")})')`; e  que o verdadeiro valor de $\beta_3$ está entre `r glue::glue('({scales::number(confint(mFit1)[4,1], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")}; {scales::number(confint(mFit1)[4,2], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")})')`.


### Análise de Resíduos

```{r fig5:analise_residuos}
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 6


mFit1_resid <- broom::augment(mFit1)

####  Gráfico de Resíduos contra Valor Médio
d1 <- mFit1_resid|>
 ggplot(aes(x = .fitted, y = rstudent(mFit1))) + 
  geom_point(color = "#234B6E") +
  geom_hline(aes(yintercept = 0), col="tomato")+
  labs(
    x = "Valores Ajustados",
    y = "Resíduos Estudentizados",
    title = "Resíduos Estudentizados vs. \nValores Ajustados")+
  scale_x_continuous(
    labels = scales::number_format(
      big.mark = ".", decimal.mark = ","))+
  scale_y_continuous(
    breaks = seq(from = -3, to = 4, by = 1),
    labels = scales::number_format(
      big.mark = ".", decimal.mark = ","))+
  theme_minimal()+
  theme(
    legend.position = "none",
    plot.title = element_text(size = 11, face = "plain"),
    axis.title = element_text(size = 8, face = "plain"),
    axis.line = element_line(size = 0.5, color = "#222222"))

####  Gráfico de normalidade dos resíduos
 d2 <- mFit1_resid %>%
   ggplot(aes(sample = .std.resid)) +
   qqplotr::stat_qq_band(alpha = 0.3) +
   qqplotr::stat_qq_point(color = "#234B6E") +
   qqplotr::stat_qq_line(linetype = 2, size = 0.2) +
   labs(
     x = "Quantil Teórico",
     y = "Quantil Amostral",
     title = "Gráfico quantil-quantil normal"
   )+
    scale_x_continuous(breaks = seq(-3,3,1))+
   scale_x_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   scale_y_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   theme_minimal()+
   theme(
     legend.position = "none",
     plot.title = element_text(size = 11, face = "plain"),
     axis.title = element_text(size = 8, face = "plain"),
     axis.line = element_line(size = 0.5, color = "#222222"))

#### Gráfico Homogeneidade de Variâncias (Locação-Escala) ----
 d3 <- mFit1_resid %>%
   ggplot(aes(x = .fitted, y = sqrt(abs(.std.resid)))) +
   geom_point(color = "#234B6E") +
   geom_smooth(
     se = T, color = "tomato", method = 'loess', formula = 'y ~ x')+
   labs(
     x = "Valores Ajustados",
     y = expression(sqrt("|Resíduos Padronizados|")),
     title = "Homogeneidade de Variâncias \n(Locação-Escala)")+
   scale_x_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   scale_y_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   theme_minimal()+
   theme(
     legend.position = "none",
     plot.title = element_text(size = 11, face = "plain"),
     axis.title = element_text(size = 8, face = "plain"),
     axis.line = element_line(size = 0.5, color = "#222222"))

 d1 + d2 + d3 +
   plot_layout(ncol = 2) +
   plot_annotation(
   title = "Figura 2: Análise de resíduos do modelo ajustado",
   tag_levels = c("A", "2"))&
   theme(
     legend.position = "none",
     plot.tag.position = c(1, 0),
     plot.tag = element_text(size = 12, hjust = 1, vjust = -3)
   )


```



A Figura 2A apresenta um comportamento simétrico dos resíduos, podendo ser constatado uma pequena variabilidade inicial e um aumento desta à medida que os valores ajustados aumentam, caracterizando uma baixa heterocedasticidade. A Figura 2C, que trata da Homogeneidade de Variâncias (Locação-Escala) ressalta que há um problema na variabilidade dos dados, ampliando a interpretação feita na análise da Figura 2A, de que há uma mudança na variabilidade dos dados, caracterizando uma certa heterocedasticidade dos dados. A Figura 2B traz o gráfico para avaliação da normalidade dos dados, mostra que apesar dos dados não estarem precisamente sobre a reta de referência, os mesmos estão contidos na região pertencente ao Intervalo de Confiança - IC, podendo assumir que há normalidade.




## Gráficos de Diagnóstico

A análise dos gráficos de diagnóstico permite avaliar as observações realizadas e conhecer a influência de cada uma delas para o madelo de regressão proposto. Assim, com base no modelo, é possível fazer as seguintes análises:

**Figura 2: Valores Ajustados e Resíduos Studentizados**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3


aaa <- ols_plot_resid_stud(mFit1)
discrepantes <- NULL
discrepantes[1:377] <- 0

for (i in 1:21) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
} 

```
A Figura 2 demonstra que os resíduos estão todos dentro dos limites esperados, com exceção da observação 7 que por pouco ultrapassou o limite inferior. Não parece ser o caso de nenhuma intervenção por conta deste valor.  

\newpage


**Figura 3: Valores Ajustados e Resíduos Padronizados.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3
aaa <- ols_plot_resid_stand(mFit1)

for (i in 1:21) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}
```

Já a análise da Figura 3, onde os resíduos foram padronizados, o número de observações que ultrapassaram os limites chegou a 4,8% do total o que é condizente com uma confiança de 95%.  

**Figura 4: Análise dos quantis teóricos e amostrais**

```{r fig3:analise_residuos}
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

ols_plot_resid_qq(mFit1)

```

A Figura 4 apresentou um bom ajuste dos resíduos à distribuição normal, sendo um pouco pior nas caudas da distribuição por uma qauntidade pequena de pontos.  

\newpage

**Figura 5: Distância de Cook.**

```{r fig4:Cook}
#| echo: false
#| warning: false
#| fig-height: 3
#| fig-width: 7

aaa <- ols_plot_cooksd_chart(mFit1)

for (i in 1:21) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}
```

A analise da distância de Cook apresentada na Figura 5 demonstra que 25 (6,6%) observações tem uma distância expressiva, mas apenas sete deles estão acima da distância de 0,025. O tretamento destes pontos pode manter os resíduos dentro do esperado com uma confiança de 95%.  

**Figura 6: Análise dos pontos de Alavanca e Resíduo Studentizado.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

aaa <- ols_plot_resid_lev(mFit1)

for (i in 1:21) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}
```

Pela Figura 6, observamos 15 observações que podem ser consideradas como *Outliers* e 21 como observações de alavanca, além de 3 com as duas características, o que representa um total de 10,3% das observações. Uma quantidade tão expressiva de dados não pode ser descartada sem o amparo de um especialista na área.  

\newpage

**Figura 7: DFBetas para as variáveis do modelo.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 8

ols_plot_dfbetas(mFit1)


showcases<-data.frame(dfbetas(mFit1))
showcases$ID<-rownames(showcases)

for (i in 1:21) {
  if (abs(showcases$air_flow[i])>.44) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$water_temp[i])>.44) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$acid_conc[i])>.44) {  
    discrepantes[i] <- discrepantes[i]+1
  }
}

```

A Figura 7 apresenta os DFBetas para cada uma das variáveis utilizadas no modelo, com uma média de 6,1% de observações discrepantes com cerca de 4 observações críticas, isto é, valores mais extemos. O tratamento destas observações podem trazer o modelo para uma situação mais compatível com a confiança estabelecida.  

**Figura 8: DfFit para as variáveis do modelo.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

aaa <- ols_plot_dffits(mFit1)

for (i in 1:21) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}

```

A Figura 8 acompanha os gráficos anteriores apresentando 6,9% de observações discrepantes, mas apenas seis valores são extremos, desta forma pode-se da mesma forma tratá-los e manter a confiança do modelo.


**Figura 9: COVRatio para as variáveis do modelo.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 9

car::crPlots(mFit1)
```

Da Figura 9 verifica-se que as variáveis "Altura", "Cintura" e "Quadil" estão mais diretamente correlacionadas com os resíduos do "Peso", o que por sua vez indica que a inclusão de observações destas variáveis apresentam maior impacto ao modelo.


### Eliminação de observações anômalas

Avaliando as observações que apresentaram comportamento anômalo nos diagnósticos dos valores ajustados e resíduos studentizados, valores ajustados e resíduos padronizados, distância de CooK, pontos de alavanca e *outliers*, análise de DfFit e todas as análises de BFBetas, chegamos as frequências de observações anômalas apresentadas na Figura 10.
```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

principais <- as.data.frame(cbind(1:21, discrepantes))
colnames(principais) <- c("Observação", "Ocorrências")

### Ajuste do Modelo + Gráfico ----
principais|>
  ggplot(aes(x = Observação, y = Ocorrências)) +
  geom_point(
    color = "#234B6E"
    )+
  labs(
    title = "Figura 10: Número de ocorrências para cada observação",
    y = 'Ocorrências',
    x = 'Observação'
  )+
  theme(legend.position = "none",
          axis.line = element_line(size = 0.5, color = "#222222"))


```

Considerando apenas as observações com 1 ou mais ocorrências temos a Tabela a seguir.

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

principais <- principais %>% filter(discrepantes>0)

principais |>
  kableExtra::kbl(
    caption = "Observações com maior número de ocorrências.",
    align = c("l", "c"), 
    row.names = F, booktabs = T, escape = F
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position")
  )|>
   kable_material()

```
Podemos intuir que essas são as observações com maior impacto negativo no modelo. Logo, eliminando-as do conjunto de dados analizados chegamos a um novo modelo dado por:


```{r }
#| echo: false
#| warning: false
dados1 <- dados1[-principais$Observação,]
n <- length(dados1$stack_loss)
Y <- as.matrix(dados1$stack_loss)
X <- as.matrix(dados1[,-c(4)])
X <- cbind(1,X)
betas <- (solve(t(X) %*% X)) %*% t(X) %*% Y
H = X %*% (solve(t(X) %*% X)) %*% t(X)
J <- matrix(1,n,n)
SQRes <- t(Y) %*% Y - t(betas) %*% t(X) %*% Y
SQReg <- t(betas) %*% t(X) %*% Y - (1/n)*t(Y) %*% J %*% Y
SQTot <- SQReg + SQRes

R2 <- round(SQReg/SQTot,3)
R2_aju <- round(1 - (SQRes/(n - 12))/(SQTot/(n -1)),3)
```


$Y_{i}^¤ =$ `r round(betas[1],3)`$+$ `r round(betas[2],3)` $X_{1i}^¤ +$ `r round(betas[3],3)` $X_{2i}^¤$ `r round(betas[4],3)` $X_{3i}^¤$ 

Onde:    
$Y_{i}^¤$ - Peso;  
$X_{1i}^¤$ - Colesterol total;  
$X_{2i}^¤$ - Glicose estabilizada;  
$X_{3i}^¤$ - Lipoproteína de alta densidade;  

Neste novo modelo o coeficiente de determinação calculado foi de $R^2=$ `r R2`, o que denota que `r R2*100`% da variância dos dados é explicada pelo modelo. O valor deste novo coeficiente permite concluir que a eliminação das observações com maior impacto no modelo foi benéfica. Pode-se calcular o coeficiente de determinação ajustado igual a $R^2_a=$ `r R2_aju`


# Conclusões

Verificou-se que a análise de variâncias foi um teste mais poderoso para identificar variáveis desnecessárias ao modelo que a analise individual das significancias das variáveis ao modelo.   

Embora se não se tenha um conhecimento específico da área estudada, foi possível realizar uma avaliação dos dados recebidos e propor um tratamento que efetivamente melhorou o modelo de regressão linear multipla realizado.  

As anomalias relatadas em cada um dos gráficos de diagnóstico elaborados foram tratadas de igual maneira contabilizando para cada observação o número de ocorrências observadas. Por este método se elencou as observações com maior potencial de prejuízo ao modelo e ao descartá-las do rol de dados avaliados obteve-se uma expressiva melhora no modelo.





















```{r dados2}
#| echo: false
#| warning: false

## Dados 2 - Import ----
dados <- read.csv("Lab07.txt", sep ="\t")

### Arrumação ----
dados <- dados|>
  janitor::clean_names()
```

