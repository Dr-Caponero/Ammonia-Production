---
title: "Produção de Amônia"
author: "Fernado Bispo, Jeff Caponero"
format:
    pdf:
      toc: true
      toc-title: Sumário
      colorlinks: true
      documentclass: report
      papersize: letter
      number-sections: false
      geometry:
        - top=30mm
        - left=30mm
        - right=20mm
        - bottom=20mm
        - heightrounded
      fig-pos: "H"
      fig-align: center
      lang: pt-BR
      # fontfamily: libertinus
      fontsize: 12pt
      include-in-header:
      - text: |
          \usepackage{caption}
          \usepackage{fontspec}
          \usepackage{xcolor}
          \usepackage{indentfirst}
          \captionsetup[table]{name=Tabela}
---

```{r pacotes}
#| echo: false
#| warning: false


# PACOTES ----

if (!require(pacman)) install.packages("pacman")

pacman::p_load(tidyverse,  janitor, stargazer,  sjmisc, summarytools,
               kableExtra, moments, ggpubr, formattable, gridExtra, 
               glue, corrplot, sessioninfo, readxl, writexl, ggthemes,
               patchwork,  plotly, lmtest, olsrr, gglm, ggplot2, rigr,
               tidymodels, GGally, skimr, performance, gtsummary)



summarytools::st_options(lang = "pt")
options(OutDec=",") 

``` 


```{r dados1}
#| echo: false
#| warning: false

## Dados 1 - Import ----

dados <- stackloss

### Arrumação ----
dados <- dados|>
  janitor::clean_names()

# Transformando as variaveis e mudando as unidades de medida.
dados1 <- dados|>
  mutate(
    acid_conc = acid_conc/10+50,
    stack_loss = stack_loss/10
  )
```


# Apresentação

O relatório desta semana está dividido em duas atividades.

# Atividade 1

## Introdução
Com base nos dados disponibilizados no *dataset* "stackloss" (do R base), que apresenta dados de 21 dias de operação de um indústria que realiza oxidação de amônia ($NH_3$) em ácido nítrico ($HNO_3$). O ácido nítrico produzido é absorvido na torre de absorção contracorrente. As informações disponíveis na base de dados referem-se a: 

-**Air fow**: que representa a taxa de operação da indústria (corrente de ar refrigerado);  
-**Water Temp**: é a temperatura de resfriamento da água que circula nos canos da torre de absorção;  
-**Acid.Conc.**: é a concentração do ácido [em porcentagem, após tratamento]; e  
-**stack.loss** (variável dependente) é o percentual (após tratamento) de amônia introduzida no processo industrial que escapa da absorção (representando uma medida(inversa) de eficiência total da indústria).  


Com base nestes dados, objetiva-se:


1. Ajustar um modelo linear múltiplo completo para estes dados. Avaliando as estimativas dos parâmetros, os resíduos e a influência das observações no ajuste do modelo, incluindo leverage, distância de Cook, DFBETAs, DFFITs e COVRATIOs.  

2. Avaliar a partir de regressão parcial e dos resíduos parciais as variáveis no modelo, bem como o pressuposto de normalidade do resíduos.

## Resultados

### Análise descritiva dos dados




```{r tab1:MedRes}
#| echo: false
#| warning: false

dados1|>
  rename(
    "Fluxo de Ar" = air_flow,
    "Temperatura da Água" = water_temp,
    "Concentração de HNO3" = acid_conc,
    "Amônia Perdida" = stack_loss
  )|>
  summarytools::descr(
    stats = c("min", "q1", "med", "mean","q3", "max",  "sd", "cv", "Skewness", "Kurtosis"),
    justify = "c",
    style = "rmarkdown",
    transpose = T
  )|>
  kbl(
    caption = "Medidas Resumo dos dados",
    digits = 2,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", 
    row.names = T, 
    booktabs = T
  )|>
  column_spec(1, bold = T)|>
  kable_styling(
    full_width = F,
    position = 'center', 
    latex_options = c("striped", "HOLD_position", "scale_down")
  )|>
  kable_material()
```



```{r fig3:BoxPlot2}
#| echo: false
#| warning: false
#| fig-height: 6
#| fig-width: 6

# BoxPlot ----
{
## b1 volume de ar----
b1 <- dados1|>
  ggplot(aes(y = air_flow)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Fluxo de Ar",
    x = "",
    y = "m³"
  )+theme_minimal(base_size = 7.5)

## b2 Temperatura da água ----
b2 <- dados1|>
  ggplot(aes(y = water_temp)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Temperatura da Água",
    x = "",
    y = "ºC"
  )+theme_minimal(base_size = 7.5)

## b3 Concentração de HNO_3 ----
b3 <- dados1|>
  ggplot(aes(y = acid_conc)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Concentração de HNO3",
    x = "",
    y = "g/L"
  )+theme_minimal(base_size = 7.5)

## b4 Perda ----
b4 <- dados1|>
  ggplot(aes(y = stack_loss)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Amônia Perdida",
    x = "",
    y = "Porcentagem"
  )+theme_minimal(base_size = 7.5)

b1 + b2 + b3 + b4 + 
  plot_layout(ncol = 2) + 
  plot_annotation(
    title = "Figura 1: BoxPlot das variáveis em análise.",
    tag_levels = c("A", "2"))&
   theme(
     legend.position = "none",
     plot.tag.position = c(1, 0),
     plot.tag = element_text(size = 12, hjust = 1, vjust = -2.2)
   )
}

```




### Modelo de Regressão Linear Multipla  

O modelo obtido pode ser representado por:

```{r }
#| echo: false
#| warning: false

n <- length(dados1$stack_loss)
Y <- as.matrix(dados1$stack_loss)
X <- as.matrix(dados1[,-4])
X <- cbind(1,X)
betas <- (solve(t(X) %*% X)) %*% t(X) %*% Y
H = X %*% (solve(t(X) %*% X)) %*% t(X)
J <- matrix(1,n,n)
SQRes <- t(Y) %*% Y - t(betas) %*% t(X) %*% Y
SQReg <- t(betas) %*% t(X) %*% Y - (1/n)*t(Y) %*% J %*% Y
SQTot <- SQReg + SQRes

R2 <- round(SQReg/SQTot,3)
R2_aju <- round(1 - (SQRes/(n - 12))/(SQTot/(n -1)),3)
```


$Y_{i}=$`r round(betas[1],3)` $+$ `r round(betas[2],3)` $X_{1i} +$ `r round(betas[3],3)` $X_{2i}$ `r round(betas[4],3)` $X_{3i}$ 

Onde:    
$Y_{i}$ - Amônia Perdida;  
$X_{1i}$ - Fluxo de Ar;  
$X_{2i}$ - Temperatura da Água;  
$X_{3i}$ - Concentração de HNO3;  

Interpretando-se o modelo pode-se dizer que para cada variável, fixadas as demais condições (_Ceteris Paribus_), temos que a porcentagem de amônia perdida é de 3,614% caso todas as demais varíáveis tenham valor zero. Há um aumento de 0,072% na perda de amônia para cada metro cúbico de ar introduzido. O aumento de cada grau Ceusius da temperatura da água provoca uma aumento de 0,13% de aumento na perda de amônia. O aumento em 1g/L na concentração do ácido nítrico reduz em 0,152% a perda de amônia. Neste modelo o coeficiente de determinação calculado foi de $R^2=$ `r R2`, o que denota que `r R2*100`% da variância dos dados é explicada pelo modelo. Pode-se calcular o coeficiente de determinação ajustado igual a $R^2_a=$ `r R2_aju`.  

### Significância do Modelo

Após o ajuste do modelo existe a necessidade de se avaliar a significância do mesmo, o teste de hipótese para tal situação será realizado, contendo as seguintes hipóteses:

$$H_0: \hat{\beta_1} = 0$$
$$H_1: \hat{\beta_1} \neq 0.$$
As Tabelas 2 e 3 trazem os principais resultados da tabela ANOVA e do Intervalo de Confiança para os parâmetros, possibilitando assim inferir sobre o modelo ajustado.


```{r teste_diag_trans}
#| echo: false
#| warning: false

## Modelo Ajustado
mFit1 <- lm(stack_loss ~ air_flow + water_temp + acid_conc, data = dados1)

fit_anova <- anova(mFit1)|>
  as.data.frame()

fit_anova <- fit_anova|>
  mutate(
    `F value` = 
      scales::number(`F value`, accuracy = 0.0001, 
                     big.mark = ".", decimal.mark = ","),
    `Pr(>F)` = 
      scales::number(`Pr(>F)`, accuracy = 0.0001, 
                     big.mark = ".", decimal.mark = ","))

fit_anova[is.na(fit_anova)] <- ""

rownames(fit_anova) <- c( "Fluxo de Ar", "Temperatura da Água", 
                          "Concentração de HNO3", "Resíduos")

fit_anova|>
  kbl(
    caption = "Análise de Variância (ANOVA)",
    format.args=list(big.mark=".", decimal.mark=","),
    digits = 3, align = "c", row.names = T, 
    booktabs = T, escape = F,
    col.names = c("$GL^1$", "Soma de Quadrados", "Quadrado Médio", "Estatística F-Snedecor", "p-valor")
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header")
  )|>
  column_spec(1, bold = T
  )|>
    footnote(
    number = c("GL: Graus de Liberdade"),
    number_title = "Legenda:",
    footnote_as_chunk = F
  )|>
  kable_material()


resultados <- cbind(confint(mFit1))
rownames(resultados) <- c("$\\hat \\beta_0$", "$\\hat \\beta_1$", "$\\hat \\beta_2$", "$\\hat \\beta_3$")

resultados|>
  kbl(
    caption = "Intervalos de Confiança para os parâmetros estimados no MRLS.",
    format.args=list(big.mark=".", decimal.mark=","),
    digits = 3, align = "c", row.names = T, booktabs = T,
    escape = F,
    col.names = c("$LI^1$", "$LS^2$")
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header")
  )|>
  column_spec(1, bold = T
  )|>
    footnote(
    symbol = "Nível de Significância de 5%.",
    symbol_title = "",
    footnote_as_chunk = T
  )|>
    footnote(
    number = c(
      "LI: Limite Inferior (2,5%)", 
      "LS: Limite Superior (97,5%)"),
    number_title = "Legenda:",
    footnote_as_chunk = F
  )|>
  kable_material()
```

Com base na Tabela 2, avaliando o p-valor é possível afirmar que o modelo é significante rejeitando assim $H_0$ que tem como pressuposto $\hat{\beta_1} = \hat{\beta_2}=\hat{\beta_3}= 0$.

Através dos Intervalos de Confiança calculados (Tabela 4) é possível afirmar com 95% de confiança que o verdadeiro valor de $\beta_0$ está entre `r glue::glue('({scales::number(confint(mFit1)[1,1], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")}; {scales::number(confint(mFit1)[1,2], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")})')`; que o verdadeiro valor de $\beta_1$ está entre `r glue::glue('({scales::number(confint(mFit1)[2,1], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")}; {scales::number(confint(mFit1)[2,2], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")})')`; que o verdadeiro valor de $\beta_2$ está entre `r glue::glue('({scales::number(confint(mFit1)[3,1], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")}; {scales::number(confint(mFit1)[3,2], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")})')`; e  que o verdadeiro valor de $\beta_3$ está entre `r glue::glue('({scales::number(confint(mFit1)[4,1], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")}; {scales::number(confint(mFit1)[4,2], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")})')`.


### Análise de Resíduos

```{r fig5:analise_residuos}
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 6


mFit1_resid <- broom::augment(mFit1)

####  Gráfico de Resíduos contra Valor Médio
d1 <- mFit1_resid|>
 ggplot(aes(x = .fitted, y = rstudent(mFit1))) + 
  geom_point(color = "#234B6E") +
  geom_hline(aes(yintercept = 0), col="tomato")+
  labs(
    x = "Valores Ajustados",
    y = "Resíduos Estudentizados",
    title = "Resíduos Estudentizados vs. \nValores Ajustados")+
  scale_x_continuous(
    labels = scales::number_format(
      big.mark = ".", decimal.mark = ","))+
  scale_y_continuous(
    breaks = seq(from = -3, to = 4, by = 1),
    labels = scales::number_format(
      big.mark = ".", decimal.mark = ","))+
  theme_minimal()+
  theme(
    legend.position = "none",
    plot.title = element_text(size = 11, face = "plain"),
    axis.title = element_text(size = 8, face = "plain"),
    axis.line = element_line(size = 0.5, color = "#222222"))

####  Gráfico de normalidade dos resíduos
 d2 <- mFit1_resid %>%
   ggplot(aes(sample = .std.resid)) +
   qqplotr::stat_qq_band(alpha = 0.3) +
   qqplotr::stat_qq_point(color = "#234B6E") +
   qqplotr::stat_qq_line(linetype = 2, size = 0.2) +
   labs(
     x = "Quantil Teórico",
     y = "Quantil Amostral",
     title = "Gráfico quantil-quantil normal"
   )+
    scale_x_continuous(breaks = seq(-3,3,1))+
   scale_x_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   scale_y_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   theme_minimal()+
   theme(
     legend.position = "none",
     plot.title = element_text(size = 11, face = "plain"),
     axis.title = element_text(size = 8, face = "plain"),
     axis.line = element_line(size = 0.5, color = "#222222"))

#### Gráfico Homogeneidade de Variâncias (Locação-Escala) ----
 d3 <- mFit1_resid %>%
   ggplot(aes(x = .fitted, y = sqrt(abs(.std.resid)))) +
   geom_point(color = "#234B6E") +
   geom_smooth(
     se = T, color = "tomato", method = 'loess', formula = 'y ~ x')+
   labs(
     x = "Valores Ajustados",
     y = expression(sqrt("|Resíduos Padronizados|")),
     title = "Homogeneidade de Variâncias \n(Locação-Escala)")+
   scale_x_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   scale_y_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   theme_minimal()+
   theme(
     legend.position = "none",
     plot.title = element_text(size = 11, face = "plain"),
     axis.title = element_text(size = 8, face = "plain"),
     axis.line = element_line(size = 0.5, color = "#222222"))

 d1 + d2 + d3 +
   plot_layout(ncol = 2) +
   plot_annotation(
   title = "Figura 2: Análise de resíduos do modelo ajustado",
   tag_levels = c("A", "2"))&
   theme(
     legend.position = "none",
     plot.tag.position = c(1, 0),
     plot.tag = element_text(size = 12, hjust = 1, vjust = -3)
   )


```



A Figura 2A apresenta um comportamento simétrico dos resíduos, podendo ser constatado uma pequena variabilidade inicial e um aumento desta à medida que os valores ajustados aumentam, caracterizando uma baixa heterocedasticidade. A Figura 2C, que trata da Homogeneidade de Variâncias (Locação-Escala) ressalta que há um problema na variabilidade dos dados, ampliando a interpretação feita na análise da Figura 2A, de que há uma mudança na variabilidade dos dados, caracterizando uma certa heterocedasticidade dos dados. A Figura 2B traz o gráfico para avaliação da normalidade dos dados, mostra que apesar dos dados não estarem precisamente sobre a reta de referência, os mesmos estão contidos na região pertencente ao Intervalo de Confiança - IC, podendo assumir que há normalidade.




### Gráficos de Diagnóstico

A análise dos gráficos de diagnóstico permite avaliar as observações realizadas e conhecer a influência de cada uma delas para o madelo de regressão proposto. Assim, com base no modelo, é possível fazer as seguintes análises:

**Figura 3: Valores Ajustados e Resíduos Studentizados**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3


aaa <- ols_plot_resid_stud(mFit1)
discrepantes <- NULL
discrepantes[1:377] <- 0

for (i in 1:21) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
} 

```
A Figura 3 demonstra que os resíduos estão todos dentro dos limites esperados, com exceção da observação 21 que por pouco ultrapassou o limite inferior. Não parece ser o caso de nenhuma intervenção por conta deste valor.  




**Figura 4: Valores Ajustados e Resíduos Padronizados.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3
aaa <- ols_plot_resid_stand(mFit1)

for (i in 1:21) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}
```

Na análise da Figura 4, onde os resíduos foram padronizados, verifica-se que apenas a observação 21 está fora do limite de aceitação.  

**Figura 5: Análise dos quantis teóricos e amostrais**

```{r fig3:analise_residuos}
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

ols_plot_resid_qq(mFit1)

```

A Figura 5 apresentou um bom ajuste dos resíduos à distribuição normal, sendo apenas um pouco pior nas caudas da distribuição.  


**Figura 6: Distância de Cook.**

```{r fig4:Cook}
#| echo: false
#| warning: false
#| fig-height: 3
#| fig-width: 7

aaa <- ols_plot_cooksd_chart(mFit1)

for (i in 1:21) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}
```

A analise da distância de Cook apresentada na Figura 6 demonstra que novamente apenas a observação 21 destoa do conjunto de observações e tem uma distância expressiva.  

**Figura 7: Análise dos pontos de Alavanca e Resíduo Studentizado.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

aaa <- ols_plot_resid_lev(mFit1)

for (i in 1:21) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}
```

Pela Figura 7, observamos 2 observações que podem ser consideradas como *Outliers* e uma como ponto de  alavanca. Interessante notar que apesar da observação 21 ter aparecido nos gráficos anteriores como uma observação anômala, aqui ela é classificada como um *outlier* o que denota uma influência menos prejudicial que a da observação 17 que aparece pela primeira vez.


**Figura 8: DFBetas para as variáveis do modelo.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 8

ols_plot_dfbetas(mFit1)


showcases<-data.frame(dfbetas(mFit1))
showcases$ID<-rownames(showcases)

for (i in 1:21) {
  if (abs(showcases$air_flow[i])>.44) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$water_temp[i])>.44) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$acid_conc[i])>.44) {  
    discrepantes[i] <- discrepantes[i]+1
  }
}

```

A Figura 8 apresenta os DFBetas para cada uma das variáveis utilizadas no modelo. Nota-se que mais uma vez a observação 21 tem comportamento anômalo.

**Figura 9: DfFit para as variáveis do modelo.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

aaa <- ols_plot_dffits(mFit1)

for (i in 1:21) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}

```

A Figura 9 acompanha os gráficos anteriores apresentando mais uma vez a observação 21 como discrepante.


**Figura 10: COVRatio para as variáveis do modelo.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 9

car::crPlots(mFit1)
```

Da Figura 10 verifica-se que as variáveis estão  diretamente correlacionadas com os resíduos da Amônia Perdida, o que por sua vez indica que a inclusão de observações destas variáveis apresentam bom impacto ao modelo.


### Eliminação de observações anômalas

Avaliando as observações que apresentaram comportamento anômalo nos diagnósticos dos valores ajustados e resíduos studentizados, valores ajustados e resíduos padronizados, distância de CooK, pontos de alavanca e *outliers*, análise de DfFit e todas as análises de BFBetas, chegamos as frequências de observações anômalas apresentadas na Figura 11.
```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

principais <- as.data.frame(cbind(1:21, discrepantes))
colnames(principais) <- c("Observação", "Ocorrências")

### Ajuste do Modelo + Gráfico ----
principais|>
  ggplot(aes(x = Observação, y = Ocorrências)) +
  geom_point(
    color = "#234B6E"
    )+
  labs(
    title = "Figura 11: Número de ocorrências para cada observação",
    y = 'Ocorrências',
    x = 'Observação'
  )+
  theme(legend.position = "none",
          axis.line = element_line(size = 0.5, color = "#222222"))


```

Considerando apenas as observações com 1 ou mais ocorrências temos a Tabela a seguir.

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

principais <- principais %>% filter(discrepantes>0)

principais |>
  kableExtra::kbl(
    caption = "Observações com maior número de ocorrências.",
    align = c("l", "c"), 
    row.names = F, booktabs = T, escape = F
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position")
  )|>
   kable_material()

```
Podemos intuir que essas são as observações com maior impacto negativo no modelo. Logo, eliminando-as do conjunto de dados analizados chegamos a um novo modelo dado por:


```{r }
#| echo: false
#| warning: false
dados1 <- dados1[-principais$Observação,]
n <- length(dados1$stack_loss)
Y <- as.matrix(dados1$stack_loss)
X <- as.matrix(dados1[,-c(4)])
X <- cbind(1,X)
betas <- (solve(t(X) %*% X)) %*% t(X) %*% Y
H = X %*% (solve(t(X) %*% X)) %*% t(X)
J <- matrix(1,n,n)
SQRes <- t(Y) %*% Y - t(betas) %*% t(X) %*% Y
SQReg <- t(betas) %*% t(X) %*% Y - (1/n)*t(Y) %*% J %*% Y
SQTot <- SQReg + SQRes

R2 <- round(SQReg/SQTot,3)
R2_aju <- round(1 - (SQRes/(n - 12))/(SQTot/(n -1)),3)
```


$Y_{i}^* =$ `r round(betas[1],3)`$+$ `r round(betas[2],3)` $X_{1i}^* +$ `r round(betas[3],3)` $X_{2i}^*$ `r round(betas[4],3)` $X_{3i}^*$ 

Onde:    
$Y_{i}^*$ - Amônia Perdida;  
$X_{1i}^*$ - Fluxo de Ar;  
$X_{2i}^*$ - Temperatura da Água;  
$X_{3i}^*$ - Concentração de HNO3; 

Neste novo modelo o coeficiente de determinação calculado foi de $R^2=$ `r R2`, o que denota que `r R2*100`% da variância dos dados é explicada pelo modelo. O valor deste novo coeficiente permite concluir que a eliminação das observações com maior impacto no modelo foi benéfica. Pode-se calcular o coeficiente de determinação ajustado igual a $R^2_a=$ `r R2_aju`


## Conclusões

<!-- Verificou-se que a análise de variâncias foi um teste mais poderoso para identificar variáveis desnecessárias ao modelo que a analise individual das significancias das variáveis ao modelo.    -->

<!-- Embora se não se tenha um conhecimento específico da área estudada, foi possível realizar uma avaliação dos dados recebidos e propor um tratamento que efetivamente melhorou o modelo de regressão linear multipla realizado.   -->

<!-- As anomalias relatadas em cada um dos gráficos de diagnóstico elaborados foram tratadas de igual maneira contabilizando para cada observação o número de ocorrências observadas. Por este método se elencou as observações com maior potencial de prejuízo ao modelo e ao descartá-las do rol de dados avaliados obteve-se uma expressiva melhora no modelo. -->

# Atividade 2

## Introdução

Para análise dos dados diários sobre evaporação do solo (EVAP), Freund (1979) identificou as seguintes variáveis preditoras:   
-**MAXAT** - temperatura do ar diária máxima;  
-**MINAT** - temperatura do ar diária mínima;  
-**AVAT** - medida de temperatura média do ar;  
-**MAXST** - temperatura máxima diária do solo;  
-**MINST** - temperatura mínima diária do solo;  
-**AVST** - medida de temperatura média do solo;  
-**MAXH** - umidade relativa diária máxima;  
-**MINH** - umidade relativa diária mínima;  
-**AVH** - umidade relativa diária média;  
-**WIND** - vento total, medido em milhas por dia.  

Com base nestes dados, objetiva-se:  
1. Ajustar um modelo completo sobre evaporação do solo (EVAP), definindo os fatores significativamente associados, o coeficiente de determinação, a avaliação da bondade do modelo completo.  
2. Determinar a correlação entre todos os preditores e a resposta. Realisando uma análise dos resíduos e dos pontos de alavanca e influentes.   
3. Investigar possíveis problemas de colinearidade, avaliando o $R^2_j$ para cada preditor e seu VIF.  
4. Melhorar o modelo pela exclusão de obseervações anômalas e pela definição de variáveis preditoras a serem incluídas no modelo.  


```{r dados2}
#| echo: false
#| warning: false

## Dados 2 - Import ----
dados <- read.csv("Lab07.txt", sep ="\t")

### Arrumação ----
dados2 <- dados|>
  janitor::clean_names()
dados2 <- dados2[,-c(1,2,3)]
```


## Resultados

### Análise descritiva dos dados

```{r tab5:MedRes}
#| echo: false
#| warning: false

dados2|>
  rename(
  "Temperatura do ar máxima" = maxat,  
  "Temperatura do ar mínima" = minat,
  "Temperatura média do ar" = avat,
  "Temperatura máxima do solo" = maxst,
  "Temperatura mínima do solo" = minst,
  "Temperatura média do solo" = avst,
  "Umidade relativa máxima" = maxh,
  "Umidade relativa mínima" = minh,
  "Umidade relativa média" = avh,
  "Vento total" = wind,
  "Evaporação do Solo" = evap 
  )|>
  summarytools::descr(
    stats = c("min", "q1", "med", "mean","q3", "max",  "sd", "cv", "Skewness", "Kurtosis"),
    justify = "c",
    style = "rmarkdown",
    transpose = T
  )|>
  kbl(
    caption = "Medidas Resumo dos dados",
    digits = 2,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", 
    row.names = T, 
    booktabs = T
  )|>
  column_spec(1, bold = T)|>
  kable_styling(
    full_width = F,
    position = 'center', 
    latex_options = c("striped", "HOLD_position", "scale_down")
  )|>
  kable_material()
```



```{r fig11:BoxPlot}
#| echo: false
#| warning: false
#| fig-height: 6
#| fig-width: 6

# BoxPlot ----
{
## b1 maxat----
b1 <- dados2|>
  ggplot(aes(y = maxat)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Temperatura \n do ar máxima",
    x = "",
    y = "ºC"
  )+theme_minimal(base_size = 7.5)

## b2 minat ----
b2 <- dados2|>
  ggplot(aes(y = minat)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Temperatura \n do ar mínima",
    x = "",
    y = "ºC"
  )+theme_minimal(base_size = 7.5)

## b3 avat ----
b3 <- dados2|>
  ggplot(aes(y = avat)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Temperatura \n média do ar",
    x = "",
    y = "ºC"
  )+theme_minimal(base_size = 7.5)

## b4 maxst ----
b4 <- dados2|>
  ggplot(aes(y = maxst)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Temperatura \n máxima do solo",
    x = "",
    y = "ºC"
  )+theme_minimal(base_size = 7.5)

## b5 minst ----
b5 <- dados2|>
  ggplot(aes(y = minst)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Temperatura \n mínima do solo",
    x = "",
    y = "ºC"
  )+theme_minimal(base_size = 7.5)

## b6 avst ----
b6 <- dados2|>
  ggplot(aes(y = avst)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Temperatura \n média do solo",
    x = "",
    y = "ºC"
  )+theme_minimal(base_size = 7.5)

## b7 maxh ----
b7 <- dados2|>
  ggplot(aes(y = maxh)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Umidade \n relativa máxima",
    x = "",
    y = "Porcentagem"
  )+theme_minimal(base_size = 7.5)

## b8 minh ----
b8 <- dados2|>
  ggplot(aes(y = minh)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Umidade \n relativa mínima",
    x = "",
    y = "Porcentagem"
  )+theme_minimal(base_size = 7.5)

## b9 avh ----
b9 <- dados2|>
  ggplot(aes(y = avh)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Umidade \n relativa média",
    x = "",
    y = "Porcentagem"
  )+theme_minimal(base_size = 7.5)

## b10 wind ----
b10 <- dados2|>
  ggplot(aes(y = wind)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Vento total",
    x = "",
    y = "Milhas por dia"
  )+theme_minimal(base_size = 7.5)

## b11 evap ----
b11 <- dados2|>
  ggplot(aes(y = evap)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Evaporação \n do Solo",
    x = "",
    y = "Litros por dia"
  )+theme_minimal(base_size = 7.5)

b1 + b2 + b3 + b4 + b5 + b6 + b7 + b8 + b9 + b10 + b11 +
  plot_layout(ncol = 4) + 
  plot_annotation(
    title = "Figura 12: BoxPlot das variáveis em análise.",
    tag_levels = c("A", "1"))&
   theme(
     legend.position = "none",
     plot.tag.position = c(1, 0),
     plot.tag = element_text(size = 12, hjust = 1, vjust = -2.2)
   )
}

```




### Modelo de Regressão Linear Multipla  

O modelo obtido pode ser representado por:

```{r }
#| echo: false
#| warning: false

n <- length(dados2$evap)
Y <- as.matrix(dados2$evap)
X <- as.matrix(dados2[,-11])
X <- cbind(1,X)
betas <- (solve(t(X) %*% X)) %*% t(X) %*% Y
H = X %*% (solve(t(X) %*% X)) %*% t(X)
J <- matrix(1,n,n)
SQRes <- t(Y) %*% Y - t(betas) %*% t(X) %*% Y
SQReg <- t(betas) %*% t(X) %*% Y - (1/n)*t(Y) %*% J %*% Y
SQTot <- SQReg + SQRes

R2 <- round(SQReg/SQTot,3)
R2_aju <- round(1 - (SQRes/(n - 12))/(SQTot/(n -1)),3)
```


$Y_{i}=$`r round(betas[1],3)` $+$ `r round(betas[2],3)` $X_{1i}$ `r round(betas[3],3)` $X_{2i}$ `r round(betas[4],3)` $X_{3i}+$ `r round(betas[5],3)` $X_{4i} +$ `r round(betas[6],3)` $X_{5i} +$ `r round(betas[7],3)` $X_{6i}$ `r round(betas[8],3)` $X_{7i}$ `r round(betas[9],3)` $X_{8i} +$ `r round(betas[10],3)` $X_{9i} +$ `r round(betas[11],3)` $X_{10i}$  

Onde:    
$Y_{i}$ - Evaporação do Solo;  
$X_{1i}$ - Temperatura do ar máxima;  
$X_{2i}$ - Temperatura do ar mínima;  
$X_{3i}$ - Temperatura do ar média;  
$X_{4i}$ - Temperatura do solo máxima;  
$X_{5i}$ - Temperatura do solo mínima;  
$X_{6i}$ - Temperatura do solo média;  
$X_{7i}$ - Umidade relativa máxima;  
$X_{8i}$ - Umidade relativa mínima;  
$X_{9i}$ - Umidade relativa média;  
$X_{10i}$ - Vento Total;


Interpretando-se o modelo pode-se dizer que para cada variável, fixadas as demais condições (_Ceteris Paribus_), temos que: 

::: incrementyal
-  a evaporação total é de 117,578L caso todas as demais varíáveis tenham valor zero;  
-  um aumento de 240mL na evaporação para cada grau Ceusius na temperatura máxima do ar;   
-  uma redução de 1,318L na evaporação para cada grau Ceusius na temperatura mínima do ar;  
-  uma redução de 116mL na evaporação para cada grau Ceusius na temperatura média do ar;  
-  um aumento de 336mL na evaporação para cada grau Ceusius na temperatura máxima do solo;  
-  um aumento de 10mL na evaporação para cada grau Ceusius na temperatura mínima do solo;  
-  um aumento de 495mL na evaporação para cada grau Ceusius na temperatura média do solo;  
-  uma redução de 877mL na evaporação para ponto porcentual de umidade relativa máxima;   
-  uma redução de 823mL na evaporação para ponto porcentual de umidade relativa mínima;   
-  um aumento de 8mL na evaporação para ponto porcentual de umidade relativa média;   
-  um aumento de 16mL na evaporação para cada milha de vento total.    
:::

Neste modelo o coeficiente de determinação calculado foi de $R^2=$ `r R2`, o que denota que `r R2*100`% da variância dos dados é explicada pelo modelo. Pode-se calcular o coeficiente de determinação ajustado igual a $R^2_a=$ `r R2_aju`.  



### Testes de Diagnósticos do Modelo

Para avaliar se o modelo atende aos pressupostos, além da análise gráfica podem ser realizados testes de diagnósticos, que são testes de hipóteses para avaliação dos pressupostos que são:

- Normalidade;

  $H_0:$ Os resíduos possuem normalidade.

  $H_1:$ Os resíduos **não** possuem normalidade.

- Homoscedasticidade (Homogeneidade de Variância);

  $H_0:$ Os resíduos possuem variância constante.

  $H_1:$ Os resíduos **não** possuem variância constante.

- Linearidade;
- Independência.

  $H_0$: Existe correlação serial entre os resíduos.
  
  $H_1$: **Não** existe correlação serial entre os resíduos.

Para tanto serão utilizados os seguintes testes:

- Shapiro-Wilk, para avaliar a Normalidade;
- Breush-Pagan, para avaliar a Homoscedasticidade;
- Durbin-Watson, para avaliar a Independência.


```{r tab4:teste-diagnostico}
#| echo: false
#| warning: false


mFit2 <- lm(evap ~ maxat + minat + avat + maxst + minst + avst + maxh + minh + avh + wind, data = dados2)
res2 <- residuals(mFit2)

##### Teste de normalidade dos resíduos ----
  #H0: normalidade
  #H1: não normalidade

# SW*
t_sw <- shapiro.test(res2)

##### Teste de homoscedasticidade dos resíduos ----
  #H0: resíduos homoscedásticos - Variância constante
  #H1: resíduos heteroscedásticos - Variância NÃO constante

# BP*
t_bp <- lmtest::bptest(mFit2, studentize = F)

# Teste deF para linearidade

# Teste de correlação serial lag 1 (Independência dos erros)
  #H0: correlacionados - existe correlação serial
  #H1: não correlacionados - não existe correlação serial ///ficou confuso no vídeo as hipoteses///

# DW
t_dw <- lmtest::dwtest(mFit2)

resultados <- round(rbind(
  t_sw$statistic,
  t_bp$statistic,
  t_dw$statistic),4)

aux <- rbind(
  round(t_sw$p.value,4),
  round(t_bp$p.value,4),
  "<0,0001")

resultados <- cbind(resultados, aux)

rownames(resultados) <- c("Shapiro-Wilk", "Breush-Pagan", "Durbin-Watson")

colnames(resultados) <- c("Estatística de teste", "p-valor")

resultados|>
  kbl(
    caption = "Testes de Diagnósticos dos Resíduos",
    digits = 5,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", row.names = T, booktabs = T
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header")
  )|>
  column_spec(1, bold = T)|>
  kable_material()
```

A Tabela 6 traz os testes de diagnósticos realizados para avaliar o modelo de regressão ajustado, conforme análise gráfica dos resíduos há a confirmação tanto da normalidade quanto da homocedasticidade de variância conforme os p-valores obtido pelos testes realizados (acima de 0,05). Porém nota-se que há dependência entre as características confirmado pelo p-valor do teste de Durbin-Watson (<0,0001), que leva a rejeição da hipótese nula ($H_0$). Este codependência era esperada uma vez que os valores médios de tempeartura e unidade relariva tem relação com seus respectivos valores máximos e mínimos. O que pode ser conferdo na matriz de correlação a seguir:





```{r correlação}
#| echo: false
#| warning: false
#| tbl-colum: page
#| fig-pos: H

b1 <- cor(dados2)
rownames(b1) <- c("Temperatura do ar máxima","Temperatura do ar mínima",
                  "Temperatura média do ar","Temperatura máxima do solo",
                  "Temperatura mínima do solo","Temperatura média do solo",
                  "Umidade relativa máxima", "Umidade relativa mínima",
                  "Umidade relativa média", "Vento total", "Evaporação do Solo")

b1 <- as.data.frame(b1[,11])
colnames(b1) <- c("Evaporação do Solo")

b1|>
  kbl(
    caption = "Matriz de correlação das variáveis do modelo",
    digits = 3,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", row.names = T, booktabs = T
  )|>
  kable_material(c("striped", "hover", "condensed"))|>
  kable_styling(
    bootstrap_options = c("striped", "hover",  "condensed"),
    full_width = F,
    position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header")
  ) |>
  column_spec(1, bold = T)|>
  kable_material()
```

### Análise de Resíduos

```{r fig13:analise_residuos}
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 6


mFit2_resid <- broom::augment(mFit2)

####  Gráfico de Resíduos contra Valor Médio
d1 <- mFit2_resid|>
 ggplot(aes(x = .fitted, y = rstudent(mFit2))) + 
  geom_point(color = "#234B6E") +
  geom_hline(aes(yintercept = 0), col="tomato")+
  labs(
    x = "Valores Ajustados",
    y = "Resíduos Estudentizados",
    title = "Resíduos Estudentizados vs. \nValores Ajustados")+
  scale_x_continuous(
    labels = scales::number_format(
      big.mark = ".", decimal.mark = ","))+
  scale_y_continuous(
    breaks = seq(from = -3, to = 4, by = 1),
    labels = scales::number_format(
      big.mark = ".", decimal.mark = ","))+
  theme_minimal()+
  theme(
    legend.position = "none",
    plot.title = element_text(size = 11, face = "plain"),
    axis.title = element_text(size = 8, face = "plain"),
    axis.line = element_line(size = 0.5, color = "#222222"))

####  Gráfico de normalidade dos resíduos
 d2 <- mFit2_resid %>%
   ggplot(aes(sample = .std.resid)) +
   qqplotr::stat_qq_band(alpha = 0.3) +
   qqplotr::stat_qq_point(color = "#234B6E") +
   qqplotr::stat_qq_line(linetype = 2, size = 0.2) +
   labs(
     x = "Quantil Teórico",
     y = "Quantil Amostral",
     title = "Gráfico quantil-quantil normal"
   )+
    scale_x_continuous(breaks = seq(-3,3,1))+
   scale_x_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   scale_y_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   theme_minimal()+
   theme(
     legend.position = "none",
     plot.title = element_text(size = 11, face = "plain"),
     axis.title = element_text(size = 8, face = "plain"),
     axis.line = element_line(size = 0.5, color = "#222222"))

#### Gráfico Homogeneidade de Variâncias (Locação-Escala) ----
 d3 <- mFit2_resid %>%
   ggplot(aes(x = .fitted, y = sqrt(abs(.std.resid)))) +
   geom_point(color = "#234B6E") +
   geom_smooth(
     se = T, color = "tomato", method = 'loess', formula = 'y ~ x')+
   labs(
     x = "Valores Ajustados",
     y = expression(sqrt("|Resíduos Padronizados|")),
     title = "Homogeneidade de Variâncias \n(Locação-Escala)")+
   scale_x_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   scale_y_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   theme_minimal()+
   theme(
     legend.position = "none",
     plot.title = element_text(size = 11, face = "plain"),
     axis.title = element_text(size = 8, face = "plain"),
     axis.line = element_line(size = 0.5, color = "#222222"))

 d1 + d2 + d3 +
   plot_layout(ncol = 2) +
   plot_annotation(
   title = "Figura 13: Análise de resíduos do modelo ajustado",
   tag_levels = c("A", "2"))&
   theme(
     legend.position = "none",
     plot.tag.position = c(1, 0),
     plot.tag = element_text(size = 12, hjust = 1, vjust = -3)
   )


```



A Figura 13A apresenta um comportamento simétrico dos resíduos, podendo ser constatado uma pequena variabilidade inicial e um aumento desta à medida que os valores ajustados aumentam, caracterizando uma baixa heterocedasticidade. A Figura 13C, que trata da Homogeneidade de Variâncias (Locação-Escala) ressalta que há um problema na variabilidade dos dados, ampliando a interpretação feita na análise da Figura 2A, de que há uma mudança na variabilidade dos dados, caracterizando uma certa heterocedasticidade dos dados. A Figura 13B traz o gráfico para avaliação da normalidade dos dados, mostra que apesar dos dados não estarem precisamente sobre a reta de referência, os mesmos estão contidos na região pertencente ao Intervalo de Confiança - IC, podendo assumir que há normalidade.




### Gráficos de Diagnóstico

A análise dos gráficos de diagnóstico permite avaliar as observações realizadas e conhecer a influência de cada uma delas para o madelo de regressão proposto. Assim, com base no modelo, é possível fazer as seguintes análises:

**Figura 14: Valores Ajustados e Resíduos Studentizados**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3


aaa <- ols_plot_resid_stud(mFit2)
discrepantes <- NULL
discrepantes[1:46] <- 0

for (i in 1:46) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
} 

```
A Figura 14 demonstra que os resíduos estão todos dentro dos limites esperados, com exceção da observação 21 que por pouco ultrapassou o limite inferior. Não parece ser o caso de nenhuma intervenção por conta deste valor.  




**Figura 15: Valores Ajustados e Resíduos Padronizados.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3
aaa <- ols_plot_resid_stand(mFit2)

for (i in 1:46) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}
```

Na análise da Figura 15, onde os resíduos foram padronizados, verifica-se que apenas a observação 21 está fora do limite de aceitação.  

**Figura 16: Análise dos quantis teóricos e amostrais**

```{r fig16:analise_residuos}
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

ols_plot_resid_qq(mFit2)

```

A Figura 16 apresentou um bom ajuste dos resíduos à distribuição normal, sendo apenas um pouco pior nas caudas da distribuição.  


**Figura 17: Distância de Cook.**

```{r fig17:Cook}
#| echo: false
#| warning: false
#| fig-height: 3
#| fig-width: 7

aaa <- ols_plot_cooksd_chart(mFit2)

for (i in 1:46) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}
```

A analise da distância de Cook apresentada na Figura 17 demonstra que novamente apenas a observação 21 destoa do conjunto de observações e tem uma distância expressiva.  

**Figura 18: Análise dos pontos de Alavanca e Resíduo Studentizado.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

aaa <- ols_plot_resid_lev(mFit2)

for (i in 1:46) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}
```

Pela Figura 18, observamos 2 observações que podem ser consideradas como *Outliers* e uma como ponto de  alavanca. Interessante notar que apesar da observação 21 ter aparecido nos gráficos anteriores como uma observação anômala, aqui ela é classificada como um *outlier* o que denota uma influência menos prejudicial que a da observação 17 que aparece pela primeira vez.


**Figura 19: DFBetas para as variáveis do modelo.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 8

ols_plot_dfbetas(mFit2)


showcases<-data.frame(dfbetas(mFit2))
showcases$ID<-rownames(showcases)

for (i in 1:46) {
  if (abs(showcases$maxat[i])>.29) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$minat[i])>.29) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$avat[i])>.29) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$maxst[i])>.29) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$minst[i])>.29) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$avst[i])>.29) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$maxh[i])>.29) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$minh[i])>.29) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$avh[i])>.29) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$wind[i])>.29) {  
    discrepantes[i] <- discrepantes[i]+1
  }
}
```

A Figura 19 apresenta os DFBetas para cada uma das variáveis utilizadas no modelo. Nota-se que mais uma vez a observação 21 tem comportamento anômalo.

**Figura 20: DfFit para as variáveis do modelo.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

aaa <- ols_plot_dffits(mFit2)

for (i in 1:46) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}

```

A Figura 20 acompanha os gráficos anteriores apresentando mais uma vez a observação 21 como discrepante.


**Figura 21: COVRatio para as variáveis do modelo.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 9

car::crPlots(mFit2)
```

Da Figura 21 verifica-se que as variáveis estão  diretamente correlacionadas com os resíduos da Amônia Perdida, o que por sua vez indica que a inclusão de observações destas variáveis apresentam bom impacto ao modelo.


###$R^2_j$ e VIF dos Preditores
```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 9

aux <- colnames(dados2)

R2_j <- NULL
VIF <- NULL
R2_j[1:10] <- 0
VIF[1:10] <- 0
for (k in 1:10){
  reg <- lm(aux[k]~aux[-c(k,11)], data = dados2)
  R2_j[k] <- summary(reg)$r.squared
  VIF[k] <- 1/(1-R2_j[k])
}
```


### Eliminação de observações anômalas

Avaliando as observações que apresentaram comportamento anômalo nos diagnósticos dos valores ajustados e resíduos studentizados, valores ajustados e resíduos padronizados, distância de CooK, pontos de alavanca e *outliers*, análise de DfFit e todas as análises de BFBetas, chegamos as frequências de observações anômalas apresentadas na Figura 11.
```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

principais <- as.data.frame(cbind(1:46, discrepantes))
colnames(principais) <- c("Observação", "Ocorrências")

### Ajuste do Modelo + Gráfico ----
principais|>
  ggplot(aes(x = Observação, y = Ocorrências)) +
  geom_point(
    color = "#234B6E"
    )+
  labs(
    title = "Figura 22: Número de ocorrências para cada observação",
    y = 'Ocorrências',
    x = 'Observação'
  )+
  theme(legend.position = "none",
          axis.line = element_line(size = 0.5, color = "#222222"))


```

Considerando apenas as observações com 2 ou mais ocorrências temos a Tabela a seguir.

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

principais <- principais %>% filter(discrepantes>1)

principais |>
  kableExtra::kbl(
    caption = "Observações com maior número de ocorrências.",
    align = c("l", "c"), 
    row.names = F, booktabs = T, escape = F
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position")
  )|>
   kable_material()

```
Podemos intuir que essas são as observações com maior impacto negativo no modelo. Logo, eliminando-as do conjunto de dados analizados chegamos a um novo modelo dado por:


```{r }
#| echo: false
#| warning: false
dados2 <- dados2[-principais$Observação,]
n <- length(dados2$evap)
Y <- as.matrix(dados2$evap)
X <- as.matrix(dados2[,-c(11)])
X <- cbind(1,X)
betas <- (solve(t(X) %*% X)) %*% t(X) %*% Y
H = X %*% (solve(t(X) %*% X)) %*% t(X)
J <- matrix(1,n,n)
SQRes <- t(Y) %*% Y - t(betas) %*% t(X) %*% Y
SQReg <- t(betas) %*% t(X) %*% Y - (1/n)*t(Y) %*% J %*% Y
SQTot <- SQReg + SQRes

R2 <- round(SQReg/SQTot,3)
R2_aju <- round(1 - (SQRes/(n - 12))/(SQTot/(n -1)),3)
```


$Y_{i}^*=$`r round(betas[1],3)` $+$ `r round(betas[2],3)` $X_{1i}^*$ `r round(betas[3],3)` $X_{2i}^* +$ `r round(betas[4],3)` $X_{3i}^*$ `r round(betas[5],3)` $X_{4i}^*$ `r round(betas[6],3)` $X_{5i}^* +$ `r round(betas[7],3)` $X_{6i}^*$ `r round(betas[8],3)` $X_{7i}^*$ `r round(betas[9],3)` $X_{8i}^* +$ `r round(betas[10],3)` $X_{9i}^* +$ `r round(betas[11],3)` $X_{10i}^*$  

Onde:    
$Y_{i}^*$ - Evaporação do Solo;  
$X_{1i}^*$ - Temperatura do ar máxima;  
$X_{2i}^*$ - Temperatura do ar mínima;  
$X_{3i}^*$ - Temperatura do ar média;  
$X_{4i}^*$ - Temperatura do solo máxima;  
$X_{5i}^*$ - Temperatura do solo mínima;  
$X_{6i}^*$ - Temperatura do solo média;  
$X_{7i}^*$ - Umidade relativa máxima;  
$X_{8i}^*$ - Umidade relativa mínima;  
$X_{9i}^*$ - Umidade relativa média;  
$X_{10i}^*$ - Vento Total;

Neste novo modelo o coeficiente de determinação calculado foi de $R^2=$ `r R2`, o que denota que `r R2*100`% da variância dos dados é explicada pelo modelo. O valor deste novo coeficiente permite concluir que a eliminação das observações com maior impacto no modelo foi benéfica. Pode-se calcular o coeficiente de determinação ajustado igual a $R^2_a=$ `r R2_aju`



## Conclusões