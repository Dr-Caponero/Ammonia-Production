---
title: "Perda de Amônia e Evaporação de Água do Solo"
author: "Fernado Bispo, Jeff Caponero"
format:
    pdf:
      toc: true
      toc-title: Sumário
      colorlinks: true
      documentclass: report
      papersize: letter
      number-sections: false
      geometry:
        - top=30mm
        - left=30mm
        - right=20mm
        - bottom=20mm
        - heightrounded
      fig-pos: "H"
      fig-align: center
      lang: pt-BR
      # fontfamily: libertinus
      fontsize: 12pt
      include-in-header:
      - text: |
          \usepackage{caption}
          \usepackage{fontspec}
          \usepackage{xcolor}
          \usepackage{indentfirst}
          \captionsetup[table]{name=Tabela}
---

```{r pacotes}
#| echo: false
#| warning: false


# PACOTES ----

if (!require(pacman)) install.packages("pacman")

pacman::p_load(tidyverse,  janitor, stargazer,  sjmisc, summarytools,
               kableExtra, moments, ggpubr, formattable, gridExtra, 
               glue, corrplot, sessioninfo, readxl, writexl, ggthemes,
               patchwork,  plotly, lmtest, olsrr, gglm, ggplot2, rigr,
               tidymodels, GGally, skimr, performance, gtsummary)



summarytools::st_options(lang = "pt")
options(OutDec=",") 

``` 


```{r dados1}
#| echo: false
#| warning: false

## Dados 1 - Import ----

dados <- stackloss

### Arrumação ----
dados <- dados|>
  janitor::clean_names()

# Transformando as variaveis e mudando as unidades de medida.
dados1 <- dados|>
  mutate(
    acid_conc = acid_conc/10+50,
    stack_loss = stack_loss/10
  )
```


# Apresentação

O relatório desta semana está dividido em duas atividades. Na primeira foi analisado um banco de dados sobre uma industria que realiza a oxidação de amônia, para o qual por meio de técnicas de regressão linear múltipla se elaborou um modelo para determinar a perda de amônia no processo. Na segunda atividade, se buscou determinar a quantidade de água perdida do solo, evaporação do solo, com base em mum banco de dados sobre propriedades do solo e do ar associadas. Nesta segunda atividade também foram utilizadas técnicas de regressão linear múltipla.

# Atividade 1

## Introdução
Com base nos dados disponibilizados no *dataset* "stackloss" (do R base), que apresenta dados de 21 dias de operação de um indústria que realiza oxidação de amônia ($NH_3$) em ácido nítrico ($HNO_3$). O ácido nítrico produzido é absorvido na torre de absorção contracorrente. As informações disponíveis na base de dados referem-se a:  

::: incrementyal
- **Air fow**: que representa a taxa de operação da indústria (corrente de ar refrigerado);  
- **Water Temp**: é a temperatura de resfriamento da água que circula nos canos da torre de absorção;  
- **Acid.Conc.**: é a concentração do ácido [em porcentagem, após tratamento]; e  
- **stack.loss** (variável dependente) é o percentual (após tratamento) de amônia introduzida no processo industrial que escapa da absorção (representando uma medida(inversa) de eficiência total da indústria).  
:::

Com base nestes dados, objetiva-se:


1. Ajustar um modelo linear múltiplo completo para estes dados. Avaliando as estimativas dos parâmetros, os resíduos e a influência das observações no ajuste do modelo, incluindo leverage, distância de Cook, DFBETAs, DFFITs e COVRATIOs.  

2. Avaliar a partir de regressão parcial e dos resíduos parciais as variáveis no modelo, bem como o pressuposto de normalidade do resíduos.

## Resultados

### Análise descritiva dos dados

É possivel realizar uma descrição prévia dos dados por meio de medidas de resumo e de gráficos do tipo box-plot como vê-se a seguir:


```{r tab1:MedRes}
#| echo: false
#| warning: false

dados1|>
  rename(
    "Fluxo de Ar" = air_flow,
    "Temperatura da Água" = water_temp,
    "Concentração de HNO3" = acid_conc,
    "Amônia Perdida" = stack_loss
  )|>
  summarytools::descr(
    stats = c("min", "q1", "med", "mean","q3", "max",  "sd", "cv", "Skewness", "Kurtosis"),
    justify = "c",
    style = "rmarkdown",
    transpose = T
  )|>
  kbl(
    caption = "Medidas Resumo dos dados",
    digits = 2,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", 
    row.names = T, 
    booktabs = T
  )|>
  column_spec(1, bold = T)|>
  kable_styling(
    full_width = F,
    position = 'center', 
    latex_options = c("striped", "HOLD_position", "scale_down")
  )|>
  kable_material()
```



```{r fig3:BoxPlot2}
#| echo: false
#| warning: false
#| fig-height: 4.5
#| fig-width: 6

# BoxPlot ----
{
## b1 volume de ar----
b1 <- dados1|>
  ggplot(aes(y = air_flow)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Fluxo de Ar",
    x = "",
    y = "m³"
  )+theme_minimal(base_size = 7.5)

## b2 Temperatura da água ----
b2 <- dados1|>
  ggplot(aes(y = water_temp)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Temperatura da Água",
    x = "",
    y = "ºC"
  )+theme_minimal(base_size = 7.5)

## b3 Concentração de HNO_3 ----
b3 <- dados1|>
  ggplot(aes(y = acid_conc)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Concentração de HNO3",
    x = "",
    y = "g/L"
  )+theme_minimal(base_size = 7.5)

## b4 Perda ----
b4 <- dados1|>
  ggplot(aes(y = stack_loss)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Amônia Perdida",
    x = "",
    y = "Porcentagem"
  )+theme_minimal(base_size = 7.5)

b1 + b2 + b3 + b4 + 
  plot_layout(ncol = 2) + 
  plot_annotation(
    title = "Figura 1: BoxPlot das variáveis em análise.",
    tag_levels = c("A", "2"))&
   theme(
     legend.position = "none",
     plot.tag.position = c(1, 0),
     plot.tag = element_text(size = 12, hjust = 1, vjust = -2.2)
   )
}

```

Nota-se uma assimetria nos dados apresentados e algumas observações que podem ser descritas como *outliers*. Entretanto é possivel propor um modelo de regressão como se segue.


### Modelo de Regressão Linear Múltipla  

O modelo de regressão múltipla obtido pode ser representado por:

```{r }
#| echo: false
#| warning: false

n <- length(dados1$stack_loss)
Y <- as.matrix(dados1$stack_loss)
X <- as.matrix(dados1[,-4])
X <- cbind(1,X)
betas <- (solve(t(X) %*% X)) %*% t(X) %*% Y
H = X %*% (solve(t(X) %*% X)) %*% t(X)
J <- matrix(1,n,n)
SQRes <- t(Y) %*% Y - t(betas) %*% t(X) %*% Y
SQReg <- t(betas) %*% t(X) %*% Y - (1/n)*t(Y) %*% J %*% Y
SQTot <- SQReg + SQRes

R2 <- round(SQReg/SQTot,3)
R2_aju <- round(1 - (SQRes/(n - 4))/(SQTot/(n -1)),3)
```


$Y_{i}=$`r round(betas[1],3)` $+$ `r round(betas[2],3)` $X_{1i} +$ `r round(betas[3],3)` $X_{2i}$ `r round(betas[4],3)` $X_{3i}$ 

Onde:    
$Y_{i}$ - Amônia Perdida;  
$X_{1i}$ - Fluxo de Ar;  
$X_{2i}$ - Temperatura da Água;  
$X_{3i}$ - Concentração de HNO3;  

Interpretando-se o modelo pode-se dizer que para cada variável, fixadas as demais condições (_Ceteris Paribus_), temos que a porcentagem de amônia perdida é de 3,614% caso todas as demais varíáveis tenham valor zero. Há um aumento de 0,072% na perda de amônia para cada metro cúbico de ar introduzido. O aumento de cada grau Ceusius da temperatura da água provoca uma aumento de 0,13% de aumento na perda de amônia. O aumento em 1g/L na concentração do ácido nítrico reduz em 0,152% a perda de amônia. Neste modelo o coeficiente de determinação calculado foi de $R^2=$ `r R2`, o que denota que `r R2*100`% da variância dos dados é explicada pelo modelo. Pode-se calcular o coeficiente de determinação ajustado igual a $R^2_a=$ `r R2_aju`.  

### Significância do Modelo

Após o ajuste do modelo existe a necessidade de se avaliar a significância do mesmo, o teste de hipótese para tal situação será realizado, contendo as seguintes hipóteses:

$$H_0: \hat{\beta_1} = 0$$
$$H_1: \hat{\beta_1} \neq 0.$$
As Tabelas 2 e 3 trazem os principais resultados da tabela ANOVA e do Intervalo de Confiança para os parâmetros, possibilitando assim inferir sobre o modelo ajustado.


```{r teste_diag_trans}
#| echo: false
#| warning: false

## Modelo Ajustado
mFit1 <- lm(stack_loss ~ air_flow + water_temp + acid_conc, data = dados1)

fit_anova <- anova(mFit1)|>
  as.data.frame()

fit_anova <- fit_anova|>
  mutate(
    `F value` = 
      scales::number(`F value`, accuracy = 0.0001, 
                     big.mark = ".", decimal.mark = ","),
    `Pr(>F)` = 
      scales::number(`Pr(>F)`, accuracy = 0.0001, 
                     big.mark = ".", decimal.mark = ","))

fit_anova[is.na(fit_anova)] <- ""

rownames(fit_anova) <- c( "Fluxo de Ar", "Temperatura da Água", 
                          "Concentração de HNO3", "Resíduos")

fit_anova|>
  kbl(
    caption = "Análise de Variância (ANOVA)",
    format.args=list(big.mark=".", decimal.mark=","),
    digits = 3, align = "c", row.names = T, 
    booktabs = T, escape = F,
    col.names = c("$GL^1$", "Soma de Quadrados", "Quadrado Médio", "Estatística F-Snedecor", "p-valor")
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "scale_down", "repeat_header")
  )|>
  column_spec(1, bold = T
  )|>
    footnote(
    number = c("GL: Graus de Liberdade"),
    number_title = "Legenda:",
    footnote_as_chunk = F
  )|>
  kable_material()


resultados <- cbind(confint(mFit1))
rownames(resultados) <- c("$\\hat \\beta_0$", "$\\hat \\beta_1$", "$\\hat \\beta_2$", "$\\hat \\beta_3$")

resultados|>
  kbl(
    caption = "Intervalos de Confiança para os parâmetros estimados no MRLS.",
    format.args=list(big.mark=".", decimal.mark=","),
    digits = 3, align = "c", row.names = T, booktabs = T,
    escape = F,
    col.names = c("$LI^1$", "$LS^2$")
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header")
  )|>
  column_spec(1, bold = T
  )|>
    footnote(
    symbol = "Nível de Significância de 5%.",
    symbol_title = "",
    footnote_as_chunk = T
  )|>
    footnote(
    number = c(
      "LI: Limite Inferior (2,5%)", 
      "LS: Limite Superior (97,5%)"),
    number_title = "Legenda:",
    footnote_as_chunk = F
  )|>
  kable_material()
```

Com base na Tabela 2, avaliando o p-valor é possível afirmar que o modelo é significante rejeitando assim $H_0$ que tem como pressuposto $\hat{\beta_1} = \hat{\beta_2}=\hat{\beta_3}= 0$. Porém, a introdução da concentração de $HNO_3$ não pode ser vista  significativa ao modelo.

Através dos Intervalos de Confiança calculados (Tabela 3) é possível afirmar com 95% de confiança que o verdadeiro valor de $\beta_0$ está entre `r glue::glue('({scales::number(confint(mFit1)[1,1], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")}; {scales::number(confint(mFit1)[1,2], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")})')`; que o verdadeiro valor de $\beta_1$ está entre `r glue::glue('({scales::number(confint(mFit1)[2,1], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")}; {scales::number(confint(mFit1)[2,2], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")})')`; que o verdadeiro valor de $\beta_2$ está entre `r glue::glue('({scales::number(confint(mFit1)[3,1], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")}; {scales::number(confint(mFit1)[3,2], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")})')`; e  que o verdadeiro valor de $\beta_3$ está entre `r glue::glue('({scales::number(confint(mFit1)[4,1], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")}; {scales::number(confint(mFit1)[4,2], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")})')`.


### Análise de Resíduos

```{r fig5:analise_residuos}
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3


mFit1_resid <- broom::augment(mFit1)

####  Gráfico de Resíduos contra Valor Médio
d1 <- mFit1_resid|>
 ggplot(aes(x = .fitted, y = rstudent(mFit1))) + 
  geom_point(color = "#234B6E") +
  geom_hline(aes(yintercept = 0), col="tomato")+
  labs(
    x = "Valores Ajustados",
    y = "Resíduos Estudentizados",
    title = "Resíduos Estudentizados vs. \nValores Ajustados")+
  scale_x_continuous(
    labels = scales::number_format(
      big.mark = ".", decimal.mark = ","))+
  scale_y_continuous(
    breaks = seq(from = -3, to = 4, by = 1),
    labels = scales::number_format(
      big.mark = ".", decimal.mark = ","))+
  theme_minimal()+
  theme(
    legend.position = "none",
    plot.title = element_text(size = 11, face = "plain"),
    axis.title = element_text(size = 8, face = "plain"),
    axis.line = element_line(size = 0.5, color = "#222222"))

####  Gráfico de normalidade dos resíduos
 d2 <- mFit1_resid %>%
   ggplot(aes(sample = .std.resid)) +
   qqplotr::stat_qq_band(alpha = 0.3) +
   qqplotr::stat_qq_point(color = "#234B6E") +
   qqplotr::stat_qq_line(linetype = 2, size = 0.2) +
   labs(
     x = "Quantil Teórico",
     y = "Quantil Amostral",
     title = "Gráfico quantil-quantil normal"
   )+
    scale_x_continuous(breaks = seq(-3,3,1))+
   scale_x_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   scale_y_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   theme_minimal()+
   theme(
     legend.position = "none",
     plot.title = element_text(size = 11, face = "plain"),
     axis.title = element_text(size = 8, face = "plain"),
     axis.line = element_line(size = 0.5, color = "#222222"))

#### Gráfico Homogeneidade de Variâncias (Locação-Escala) ----
 d3 <- mFit1_resid %>%
   ggplot(aes(x = .fitted, y = sqrt(abs(.std.resid)))) +
   geom_point(color = "#234B6E") +
   geom_smooth(
     se = T, color = "tomato", method = 'loess', formula = 'y ~ x')+
   labs(
     x = "Valores Ajustados",
     y = expression(sqrt("|Resíduos Padronizados|")),
     title = "Homogeneidade de Variâncias \n(Locação-Escala)")+
   scale_x_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   scale_y_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   theme_minimal()+
   theme(
     legend.position = "none",
     plot.title = element_text(size = 11, face = "plain"),
     axis.title = element_text(size = 8, face = "plain"),
     axis.line = element_line(size = 0.5, color = "#222222"))

 d1 + d2 + d3 +
   plot_layout(ncol = 3) +
   plot_annotation(
   title = "Figura 2: Análise de resíduos do modelo ajustado",
   tag_levels = c("A", "2"))&
   theme(
     legend.position = "none",
     plot.tag.position = c(1, 0),
     plot.tag = element_text(size = 12, hjust = 1, vjust = -3)
   )


```



A Figura 2A apresenta um comportamento simétrico dos resíduos, podendo ser constatado uma pequena variabilidade inicial e um aumento desta à medida que os valores ajustados aumentam, caracterizando uma baixa heterocedasticidade. A Figura 2C, que trata da Homogeneidade de Variâncias (Locação-Escala) ressalta que há um problema na variabilidade dos dados, ampliando a interpretação feita na análise da Figura 2A, de que há uma mudança na variabilidade dos dados, caracterizando uma certa heterocedasticidade dos dados. A Figura 2B traz o gráfico para avaliação da normalidade dos dados, mostra que apesar dos dados não estarem precisamente sobre a reta de referência, os mesmos estão contidos na região pertencente ao Intervalo de Confiança - IC, podendo assumir que há normalidade.




### Gráficos de Diagnóstico

A análise dos gráficos de diagnóstico permite avaliar as observações realizadas e conhecer a influência de cada uma delas para o madelo de regressão proposto. Assim, com base no modelo, é possível fazer as seguintes análises:

\newpage

**Figura 3: Valores Ajustados e Resíduos Studentizados**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3


aaa <- ols_plot_resid_stud(mFit1)
discrepantes <- NULL
discrepantes[1:377] <- 0

for (i in 1:21) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
} 

```
A Figura 3 demonstra que os resíduos estão todos dentro dos limites esperados, com exceção da observação 21 que por pouco ultrapassou o limite inferior. Não parece ser o caso de nenhuma intervenção por conta deste valor.  




**Figura 4: Valores Ajustados e Resíduos Padronizados.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3
aaa <- ols_plot_resid_stand(mFit1)

for (i in 1:21) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}
```

Na análise da Figura 4, onde os resíduos foram padronizados, verifica-se que apenas a observação 21 está fora do limite de aceitação.  

\newpage

**Figura 5: Distância de Cook.**

```{r fig4:Cook}
#| echo: false
#| warning: false
#| fig-height: 3
#| fig-width: 7

aaa <- ols_plot_cooksd_chart(mFit1)

for (i in 1:21) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}
```

A analise da distância de Cook apresentada na Figura 5 demonstra que novamente apenas a observação 21 destoa do conjunto de observações e tem uma distância expressiva.



**Figura 6: Análise dos pontos de Alavanca e Resíduo Studentizado.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

aaa <- ols_plot_resid_lev(mFit1)

for (i in 1:21) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}
```

Pela Figura 6, observamos 2 observações que podem ser consideradas como *Outliers* e uma como ponto de  alavanca. Interessante notar que apesar da observação 21 ter aparecido nos gráficos anteriores como uma observação anômala, aqui ela é classificada como um *outlier* o que denota uma influência menos prejudicial que a da observação 17 que aparece pela primeira vez.

\newpage 

**Figura 7: DFBetas para as variáveis do modelo.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 7

ols_plot_dfbetas(mFit1)


showcases<-data.frame(dfbetas(mFit1))
showcases$ID<-rownames(showcases)

for (i in 1:21) {
  if (abs(showcases$air_flow[i])>.44) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$water_temp[i])>.44) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$acid_conc[i])>.44) {  
    discrepantes[i] <- discrepantes[i]+1
  }
}

```

A Figura 7 apresenta os DFBetas para cada uma das variáveis utilizadas no modelo. Nota-se que mais uma vez a observação 21 tem comportamento anômalo.

\newpage 

**Figura 8: DfFit para as variáveis do modelo.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

aaa <- ols_plot_dffits(mFit1)

for (i in 1:21) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}

```

A Figura 8 acompanha os gráficos anteriores apresentando mais uma vez a observação 21 como discrepante.



**Figura 9: COVRatio para as variáveis do modelo.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 5

car::crPlots(mFit1)
```

Da Figura 9 verifica-se que as variáveis estão  diretamente correlacionadas com os resíduos da Amônia Perdida, o que por sua vez indica que a inclusão de observações destas variáveis apresentam bom impacto ao modelo.


### Eliminação de observações anômalas

Avaliando as observações que apresentaram comportamento anômalo nos diagnósticos dos valores ajustados e resíduos studentizados, valores ajustados e resíduos padronizados, distância de CooK, pontos de alavanca e *outliers*, análise de DfFit e todas as análises de BFBetas, chegamos as frequências de observações anômalas apresentadas na Figura 10.
```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

principais <- as.data.frame(cbind(1:21, discrepantes))
colnames(principais) <- c("Observação", "Ocorrências")

### Ajuste do Modelo + Gráfico ----
principais|>
  ggplot(aes(x = Observação, y = Ocorrências)) +
  geom_point(
    color = "#234B6E"
    )+
  labs(
    title = "Figura 10: Número de ocorrências para cada observação",
    y = 'Ocorrências',
    x = 'Observação'
  )+
  theme(legend.position = "none",
          axis.line = element_line(size = 0.5, color = "#222222"))


```

Considerando apenas as observações com 1 ou mais ocorrências temos a Tabela a seguir.

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

principais <- principais %>% filter(discrepantes>0)

principais |>
  kableExtra::kbl(
    caption = "Observações com maior número de ocorrências.",
    align = c("l", "c"), 
    row.names = F, booktabs = T, escape = F
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position")
  )|>
   kable_material()

```
Podemos intuir que essas são as observações com maior impacto negativo no modelo. Logo, eliminando-as do conjunto de dados analizados e com base na análise da variância feita na Tabela 2, a eliminação da variável "Concentração de $HNO_3$", chega-se a um novo modelo dado por:


```{r }
#| echo: false
#| warning: false
dados1 <- dados1[-principais$Observação,]
n <- length(dados1$stack_loss)
Y <- as.matrix(dados1$stack_loss)
X <- as.matrix(dados1[,-c(3,4)])
X <- cbind(1,X)
betas <- (solve(t(X) %*% X)) %*% t(X) %*% Y
H = X %*% (solve(t(X) %*% X)) %*% t(X)
J <- matrix(1,n,n)
SQRes <- t(Y) %*% Y - t(betas) %*% t(X) %*% Y
SQReg <- t(betas) %*% t(X) %*% Y - (1/n)*t(Y) %*% J %*% Y
SQTot <- SQReg + SQRes

R2 <- round(SQReg/SQTot,3)
R2_aju <- round(1 - (SQRes/(n - 3))/(SQTot/(n -1)),3)
```


$Y_{i}^* =$ `r round(betas[1],3)`$+$ `r round(betas[2],3)` $X_{1i}^* +$ `r round(betas[3],3)` $X_{2i}^*$ 

Onde:    
$Y_{i}^*$ - Amônia Perdida;  
$X_{1i}^*$ - Fluxo de Ar;  
$X_{2i}^*$ - Temperatura da Água;  
 

Neste novo modelo o coeficiente de determinação calculado foi de $R^2=$ `r R2`, o que denota que `r R2*100`% da variância dos dados é explicada pelo modelo. O valor deste novo coeficiente permite concluir que a eliminação das observações com maior impacto e da variável com pouca relevância ao modelo foi benéfica. Pode-se calcular o coeficiente de determinação ajustado igual a $R^2_a=$ `r R2_aju`


## Conclusões

Verificou-se que embora os dados apresentem certa assimetria é possível propor um modelo de regressão linear múltipla para conhecer a quantidade de amônia perdida no processo.

Embora se não se tenha um conhecimento específico da área estudada, foi possível realizar uma avaliação dos dados recebidos e propor um tratamento que efetivamente melhorou o modelo de regressão linear multipla realizado.

As anomalias relatadas em cada um dos gráficos de diagnóstico elaborados foram tratadas de igual maneira contabilizando para cada observação o número de ocorrências observadas. Por este método se elencou as observações com maior potencial de prejuízo ao modelo e ao descartá-las do rol de dados avaliados obteve-se uma expressiva melhora no modelo.

O modelo final obtido, embora muito mais simples que o inicial, foi capaz de ter um resultado expressivamente melhor confirmando a eficácia do uso das técnicas adotadas.

# Atividade 2

## Introdução

Para análise dos dados diários sobre evaporação do solo (EVAP), Freund (1979) identificou as seguintes variáveis preditoras:   

::: incrementyal
- **MAXAT** - temperatura do ar diária máxima;
- **MINAT** - temperatura do ar diária mínima;
- **AVAT** - medida de temperatura média do ar;
- **MAXST** - temperatura máxima diária do solo;
- **MINST** - temperatura mínima diária do solo;
- **AVST** - medida de temperatura média do solo;
- **MAXH** - umidade relativa diária máxima;
- **MINH** - umidade relativa diária mínima;
- **AVH** - umidade relativa diária média;
- **WIND** - vento total, medido em milhas por dia.
:::
Com base nestes dados, objetiva-se:  

1. Ajustar um modelo completo sobre evaporação do solo (EVAP), definindo os fatores significativamente associados, o coeficiente de determinação, a avaliação da bondade do modelo completo.  
2. Determinar a correlação entre todos os preditores e a resposta. Realisando uma análise dos resíduos e dos pontos de alavanca e influentes.   
3. Investigar possíveis problemas de colinearidade, avaliando o $R^2_j$ para cada preditor e seu VIF.  
4. Melhorar o modelo pela exclusão de obseervações anômalas e pela definição de variáveis preditoras a serem incluídas no modelo.  


```{r dados2}
#| echo: false
#| warning: false

## Dados 2 - Import ----
dados <- read.csv("Lab07.txt", sep ="\t")

### Arrumação ----
dados2 <- dados|>
  janitor::clean_names()
dados2 <- dados2[,-c(1,2,3)]
dados2 <- dados2 %>% mutate(
  ampat = maxat - minat,
  ampst = maxst - minst,
  amph = maxh - minh
)
dados2 <- dados2[,-c(1,2,4,5,7,8)]
dados2 <- dados2 %>%
  select(ampat, avat, ampst, avst, amph, avh, wind, evap)
```


## Resultados

### Tratamento dos dados

A fim de reduzir o número de variáveis do modelo, com uma perda de informação aceitável as variáveis de máximo e mínimo foram substituídas por uma variável de amplitude, isto é, a amplitude térmica representa a diferença entre o valor máximo e mínimo observados, criando assim as seguintes variáveis:

::: incrementyal
- **AMPAT** -  Amplitude térmica do ar diária;
- **AMPST** - Amplitude térmica do solo diária;
- **AMPH** - Amplitude da umidade relativa diária.
:::



### Análise descritiva dos dados

Similarmente ao que foi feito na primeira atividade, é possivel realizar uma descrição prévia dos dados por meio de medidas de resumo e de gráficos do tipo box-plot como vê-se a seguir:

```{r tab5:MedRes}
#| echo: false
#| warning: false

dados2|>
  rename(
  "Amplitude térmica do ar " = ampat,  
  "Temperatura média do ar" = avat,
  "Amplitude témica do solo" = ampst,
  "Temperatura média do solo" = avst,
  "Amplitude da umidade relativa" = amph,
  "Umidade relativa média" = avh,
  "Vento total" = wind,
  "Evaporação do Solo" = evap 
  )|>
  summarytools::descr(
    stats = c("min", "q1", "med", "mean","q3", "max",  "sd", "cv", "Skewness", "Kurtosis"),
    justify = "c",
    style = "rmarkdown",
    transpose = T
  )|>
  kbl(
    caption = "Medidas Resumo dos dados",
    digits = 2,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", 
    row.names = T, 
    booktabs = T
  )|>
  column_spec(1, bold = T)|>
  kable_material(c("striped", "hover", "condensed"))|>
  kable_styling(
    bootstrap_options = c("striped", "hover",  "condensed"),
    full_width = F,
    position = 'center', 
    latex_options = c("striped", "HOLD_position", "scale_down","repeat_header")
  )|>
  kable_material()
```



```{r fig11:BoxPlot}
#| echo: false
#| warning: false
#| fig-height: 6
#| fig-width: 6

# BoxPlot ----
{
## b1 ampat----
b1 <- dados2|>
  ggplot(aes(y = ampat)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Amplitude \n térmica do ar",
    x = "",
    y = "ºC"
  )+theme_minimal(base_size = 7.5)


## b3 avat ----
b3 <- dados2|>
  ggplot(aes(y = avat)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Temperatura \n média do ar",
    x = "",
    y = "ºC"
  )+theme_minimal(base_size = 7.5)

## b4 ampst ----
b4 <- dados2|>
  ggplot(aes(y = ampst)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Amplitude \n térmica do solo",
    x = "",
    y = "ºC"
  )+theme_minimal(base_size = 7.5)

## b6 avst ----
b6 <- dados2|>
  ggplot(aes(y = avst)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Temperatura \n média do solo",
    x = "",
    y = "ºC"
  )+theme_minimal(base_size = 7.5)

## b7 amph ----
b7 <- dados2|>
  ggplot(aes(y = amph)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Amplitude da \n umidade relativa",
    x = "",
    y = "Porcentagem"
  )+theme_minimal(base_size = 7.5)


## b9 avh ----
b9 <- dados2|>
  ggplot(aes(y = avh)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Umidade \n relativa média",
    x = "",
    y = "Porcentagem"
  )+theme_minimal(base_size = 7.5)

## b10 wind ----
b10 <- dados2|>
  ggplot(aes(y = wind)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Vento total",
    x = "",
    y = "Milhas por dia"
  )+theme_minimal(base_size = 7.5)

## b11 evap ----
b11 <- dados2|>
  ggplot(aes(y = evap)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Evaporação \n do Solo",
    x = "",
    y = "Litros por dia"
  )+theme_minimal(base_size = 7.5)

b1 + b3 + b4 + b6 + b7 + b9 + b10 + b11 +
  plot_layout(ncol = 4) + 
  plot_annotation(
    title = "Figura 11: BoxPlot das variáveis em análise.",
    tag_levels = c("A", "1"))&
   theme(
     legend.position = "none",
     plot.tag.position = c(1, 0),
     plot.tag = element_text(size = 12, hjust = 1, vjust = -2.2)
   )
}

```


Na maioria das variáveis percebe-se uma assimetria nos dados. O número de *outliers* é razoável e precisará ser investigado mais adiante. Entretanto, já pode se verificar uma inconsistência nos dados que já pode ser eliminada: há uma observação negativa na amplitude térmica do ar, o que é inconcebível. Embora as condições não sejam ideiais pode-se propor um modelo de regressão para se melhor conhecer a evaporação de água pelo solo.

### Modelo de Regressão Linear Múltipla  

O modelo de regressão lineal múltipla inicialmente  obtido pode ser representado por:

```{r }
#| echo: false
#| warning: false
dados2 <- dados2[-7,]
n <- length(dados2$evap)
Y <- as.matrix(dados2$evap)
X <- as.matrix(dados2[,-8])
X <- cbind(1,X)
betas <- (solve(t(X) %*% X)) %*% t(X) %*% Y
H = X %*% (solve(t(X) %*% X)) %*% t(X)
J <- matrix(1,n,n)
SQRes <- t(Y) %*% Y - t(betas) %*% t(X) %*% Y
SQReg <- t(betas) %*% t(X) %*% Y - (1/n)*t(Y) %*% J %*% Y
SQTot <- SQReg + SQRes

R2 <- round(SQReg/SQTot,3)
R2_aju <- round(1 - (SQRes/(n - 9))/(SQTot/(n -1)),3)
```


$Y_{i}=$`r round(betas[1],3)` $+$ `r round(betas[2],3)` $X_{1i}+$ `r round(betas[3],3)` $X_{2i}+$ `r round(betas[4],3)` $X_{3i}$ `r round(betas[5],3)` $X_{4i} +$ `r round(betas[6],3)` $X_{5i} +$ `r round(betas[7],3)` $X_{6i}+$ `r round(betas[8],3)` $X_{7i}$ 

Onde:    
$Y_{i}$ - Evaporação do Solo;  
$X_{1i}$ - Amplitude térmica do ar;  
$X_{2i}$ - Temperatura do ar média;  
$X_{3i}$ - Amplitude térmica do solo;;  
$X_{4i}$ - Temperatura do solo média;  
$X_{5i}$ - Amplitude da umidade relativa;  
$X_{6i}$ - Umidade relativa média;  
$X_{7i}$ - Vento Total.  



Interpretando-se o modelo pode-se dizer que para cada variável, fixadas as demais condições (_Ceteris Paribus_), temos que: 

::: incrementyal
-  um aumento de 198mL na evaporação para cada grau Ceusius na amplitude térmica do ar;   
-  um aumento de 463mL na evaporação para cada grau Ceusius na temperatura média do ar;  
-  um aumento de 874mL na evaporação para cada grau Ceusius na amplitude térmica do solo;  
-  uma redução de 236mL na evaporação para cada grau Ceusius na temperatura média do solo;  
-  um aumento de 711mL na evaporação para ponto porcentual de amplitude da umidade relativa;  
-  um aumento de 11mL na evaporação para ponto porcentual de umidade relativa média;   
-  um aumento de 17mL na evaporação para cada milha de vento total.    
:::

Neste modelo o coeficiente de determinação calculado foi de $R^2=$ `r R2`, o que denota que `r R2*100`% da variância dos dados é explicada pelo modelo. Pode-se calcular o coeficiente de determinação ajustado igual a $R^2_a=$ `r R2_aju`.  



### Testes de Diagnósticos do Modelo

Para avaliar se o modelo atende aos pressupostos, além da análise gráfica podem ser realizados testes de diagnósticos, que são testes de hipóteses para avaliação dos pressupostos que são:

- Normalidade;

  $H_0:$ Os resíduos possuem normalidade.

  $H_1:$ Os resíduos **não** possuem normalidade.

- Homoscedasticidade (Homogeneidade de Variância);

  $H_0:$ Os resíduos possuem variância constante.

  $H_1:$ Os resíduos **não** possuem variância constante.

- Linearidade;
- Independência.

  $H_0$: Existe correlação serial entre os resíduos.
  
  $H_1$: **Não** existe correlação serial entre os resíduos.

Para tanto serão utilizados os seguintes testes:

- Shapiro-Wilk, para avaliar a Normalidade;
- Breush-Pagan, para avaliar a Homoscedasticidade;
- Durbin-Watson, para avaliar a Independência.


```{r tab4:teste-diagnostico}
#| echo: false
#| warning: false


mFit2 <- lm(evap ~ ampat + avat + ampst + avst + amph + avh + wind, data = dados2)
res2 <- residuals(mFit2)

##### Teste de normalidade dos resíduos ----
  #H0: normalidade
  #H1: não normalidade

# SW*
t_sw <- shapiro.test(res2)

##### Teste de homoscedasticidade dos resíduos ----
  #H0: resíduos homoscedásticos - Variância constante
  #H1: resíduos heteroscedásticos - Variância NÃO constante

# BP*
t_bp <- lmtest::bptest(mFit2, studentize = F)

# Teste deF para linearidade

# Teste de correlação serial lag 1 (Independência dos erros)
  #H0: correlacionados - existe correlação serial
  #H1: não correlacionados - não existe correlação serial ///ficou confuso no vídeo as hipoteses///

# DW
t_dw <- lmtest::dwtest(mFit2)

resultados <- round(rbind(
  t_sw$statistic,
  t_bp$statistic,
  t_dw$statistic),4)

aux <- rbind(
  round(t_sw$p.value,4),
  round(t_bp$p.value,4),
  round(t_dw$p.value,4))

resultados <- cbind(resultados, aux)

rownames(resultados) <- c("Shapiro-Wilk", "Breush-Pagan", "Durbin-Watson")

colnames(resultados) <- c("Estatística de teste", "p-valor")

resultados|>
  kbl(
    caption = "Testes de Diagnósticos dos Resíduos",
    digits = 5,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", row.names = T, booktabs = T
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header")
  )|>
  column_spec(1, bold = T)|>
  kable_material()
```

A Tabela 6 traz os testes de diagnósticos realizados para avaliar o modelo de regressão ajustado. Verifica-se que a hipótese de nula da homocedasticidade deve ser rejeitada com um nível de significância de 5%, uma vez que o teste de Breush-Pagam obteve um p-valor menor que 0.05. A normalidade da distribuição foi também rejeitada como indica o p-valor do teste de Shapiro-Wilk. Nota-se ainda que há dependência entre as características confirmado pelo p-valor do teste de Durbin-Watson. Este codependência era esperada uma vez que os valores médios de tempeartura do ar e do solo são dependente bem como a unidade relativa. O que pode ser conferdo na matriz de correlação a seguir.


### Correlação entre as variáveis do modelo


A correlação entre as variáveis do modelo pode ser medida pelo coeficiente de correlação entre elas.

```{r correlação}
#| echo: false
#| warning: false
#| tbl-colum: page
#| fig-pos: H

b1 <- cor(dados2)
rownames(b1) <- c("Amplitude térmica do ar","Temperatura média do ar ",
                  "Amplitude térmica do solo","Temperatura média do solo",
                  "Amplitude da umidade relativa","Umidade relativa média",
                  "Vento total", "Evaporação do Solo")

b1 <- as.data.frame(b1[,8])
colnames(b1) <- c("Evaporação do Solo")

b1|>
  kbl(
    caption = "Matriz de correlação das variáveis do modelo",
    digits = 3,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", row.names = T, booktabs = T
  )|>
  kable_material(c("striped", "hover", "condensed"))|>
  kable_styling(
    bootstrap_options = c("striped", "hover",  "condensed"),
    full_width = F,
    position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header")
  ) |>
  column_spec(1, bold = T)|>
  kable_material()
```

Nota-se que as variaveis mais fortemente correlacionadas à evaporação de água no solo no modelo proposto são as temperaturas média do ar e a amplitude térmica do solo, e as menos correlacionadas são a umidade realtiva média e a quantidade total de ventos.

### Significância das variáveis do Modelo

Após o ajuste do modelo existe a necessidade de se avaliar a significância do mesmo, o teste de hipótese para tal situação será realizado, contendo as seguintes hipóteses:

$$H_0: \hat{\beta_1} = 0$$
$$H_1: \hat{\beta_1} \neq 0.$$
As Tabelas 2 e 3 trazem os principais resultados da tabela ANOVA e do Intervalo de Confiança para os parâmetros, possibilitando assim inferir sobre o modelo ajustado.


```{r teste_diag_trans2}
#| echo: false
#| warning: false

## Modelo Ajustado
mFit2 <- lm(evap ~  ampat + avat + ampst + avst + amph + avh + wind, data = dados2)

fit_anova <- anova(mFit2)|>
  as.data.frame()

fit_anova <- fit_anova|>
  mutate(
    `F value` = 
      scales::number(`F value`, accuracy = 0.0001, 
                     big.mark = ".", decimal.mark = ","),
    `Pr(>F)` = 
      scales::number(`Pr(>F)`, accuracy = 0.0001, 
                     big.mark = ".", decimal.mark = ","))

fit_anova[is.na(fit_anova)] <- ""

rownames(fit_anova) <- c("Amplitude térmica do ar","Temperatura média do ar ",
                  "Amplitude térmica do solo","Temperatura média do solo",
                  "Amplitude da umidade relativa","Umidade relativa média",
                  "Vento total", "Resíduos")

fit_anova|>
  kbl(
    caption = "Análise de Variância (ANOVA)",
    format.args=list(big.mark=".", decimal.mark=","),
    digits = 3, align = "c", row.names = T, 
    booktabs = T, escape = F,
    col.names = c("$GL^1$", "Soma de Quadrados", "Quadrado Médio", "Estatística F-Snedecor", "p-valor")
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "scale_down", "repeat_header")
  )|>
  column_spec(1, bold = T
  )|>
    footnote(
    number = c("GL: Graus de Liberdade"),
    number_title = "Legenda:",
    footnote_as_chunk = F
  )|>
  kable_material()


```

Com base na Tabela 2, avaliando o p-valor é possível afirmar que o modelo é significante rejeitando assim $H_0$ que tem como pressuposto $\hat{\beta_j} = 0$. Porém, a introdução das variáveis: Temperatura média do solo, Umidade Relativa média e Vento total não podem ser vistas como significativas ao modelo.

### Análise de Resíduos

```{r fig13:analise_residuos}
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3


mFit2_resid <- broom::augment(mFit2)

####  Gráfico de Resíduos contra Valor Médio
d1 <- mFit2_resid|>
 ggplot(aes(x = .fitted, y = rstudent(mFit2))) + 
  geom_point(color = "#234B6E") +
  geom_hline(aes(yintercept = 0), col="tomato")+
  labs(
    x = "Valores Ajustados",
    y = "Resíduos Estudentizados",
    title = "Resíduos Estudentizados vs. \nValores Ajustados")+
  scale_x_continuous(
    labels = scales::number_format(
      big.mark = ".", decimal.mark = ","))+
  scale_y_continuous(
    breaks = seq(from = -3, to = 4, by = 1),
    labels = scales::number_format(
      big.mark = ".", decimal.mark = ","))+
  theme_minimal()+
  theme(
    legend.position = "none",
    plot.title = element_text(size = 11, face = "plain"),
    axis.title = element_text(size = 8, face = "plain"),
    axis.line = element_line(size = 0.5, color = "#222222"))

####  Gráfico de normalidade dos resíduos
 d2 <- mFit2_resid %>%
   ggplot(aes(sample = .std.resid)) +
   qqplotr::stat_qq_band(alpha = 0.3) +
   qqplotr::stat_qq_point(color = "#234B6E") +
   qqplotr::stat_qq_line(linetype = 2, size = 0.2) +
   labs(
     x = "Quantil Teórico",
     y = "Quantil Amostral",
     title = "Gráfico quantil-quantil normal"
   )+
    scale_x_continuous(breaks = seq(-3,3,1))+
   scale_x_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   scale_y_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   theme_minimal()+
   theme(
     legend.position = "none",
     plot.title = element_text(size = 11, face = "plain"),
     axis.title = element_text(size = 8, face = "plain"),
     axis.line = element_line(size = 0.5, color = "#222222"))

#### Gráfico Homogeneidade de Variâncias (Locação-Escala) ----
 d3 <- mFit2_resid %>%
   ggplot(aes(x = .fitted, y = sqrt(abs(.std.resid)))) +
   geom_point(color = "#234B6E") +
   geom_smooth(
     se = T, color = "tomato", method = 'loess', formula = 'y ~ x')+
   labs(
     x = "Valores Ajustados",
     y = expression(sqrt("|Resíduos Padronizados|")),
     title = "Homogeneidade de \n Variâncias \n(Locação-Escala)")+
   scale_x_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   scale_y_continuous(
     labels = scales::number_format(
       big.mark = ".", decimal.mark = ","))+
   theme_minimal()+
   theme(
     legend.position = "none",
     plot.title = element_text(size = 11, face = "plain"),
     axis.title = element_text(size = 8, face = "plain"),
     axis.line = element_line(size = 0.5, color = "#222222"))

 d1 + d2 + d3 +
   plot_layout(ncol = 3) +
   plot_annotation(
   title = "Figura 12: Análise de resíduos do modelo ajustado",
   tag_levels = c("A", "2"))&
   theme(
     legend.position = "none",
     plot.tag.position = c(1, 0),
     plot.tag = element_text(size = 12, hjust = 1, vjust = -3)
   )


```



A Figura 12A apresenta um comportamento assimétrico dos resíduos, podendo ser constatado uma pequena variabilidade inicial e um aumento desta à medida que os valores ajustados aumentam, caracterizando uma maior heterocedasticidade. A Figura 12C, que trata da Homogeneidade de Variâncias (Locação-Escala) ressalta que há um problema na variabilidade dos dados, ampliando a interpretação feita na análise da Figura 12A, de que há uma mudança na variabilidade dos dados, caracterizando uma heterocedasticidade dos dados. A Figura 12B traz o gráfico para avaliação da normalidade dos dados, mostra que os dados não estão precisamente sobre a reta de referência, especialmente nas caudas da distribuição onde fogem inclusive da região pertencente ao Intervalo de Confiança - IC, podendo assumir que não há normalidade.




### Gráficos de Diagnóstico

A análise dos gráficos de diagnóstico permite avaliar as observações realizadas e conhecer a influência de cada uma delas para o madelo de regressão proposto. Assim, com base no modelo, é possível fazer as seguintes análises:

\newpage

**Figura 13: Valores Ajustados e Resíduos Studentizados**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3


aaa <- ols_plot_resid_stud(mFit2)
discrepantes <- NULL
discrepantes[1:46] <- 0

for (i in 1:46) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
} 

```
A Figura 13 demonstra que os resíduos estão todos dentro dos limites esperados, com exceção da observação 40 que ultrapassa o limite inferior. Não parece ser o caso de nenhuma intervenção por conta deste valor.  




**Figura 14: Valores Ajustados e Resíduos Padronizados.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3
aaa <- ols_plot_resid_stand(mFit2)

for (i in 1:46) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}
```

Na análise da Figura 14, onde os resíduos foram padronizados, verifica-se que a mesma observação anterior (40) está além do limite de aceitação, bem como outras três foram detectadas: 31, 32 e 38.

\newpage

**Figura 15: Distância de Cook.**

```{r fig17:Cook}
#| echo: false
#| warning: false
#| fig-height: 3
#| fig-width: 7

aaa <- ols_plot_cooksd_chart(mFit2)

for (i in 1:46) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}
```

A analise da distância de Cook apresentada na Figura 15 demonstra que a observação 38 destoa do conjunto de observações e tem uma distância muito expressiva.  




**Figura 16: Análise dos pontos de Alavanca e Resíduo Studentizado.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

aaa <- ols_plot_resid_lev(mFit2)

for (i in 1:46) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}
```

Pela Figura 16, observamos quatro observações que podem ser consideradas como *Outliers* e uma como ponto de  alavanca e a observação 38 com as duas características sendo possívelmente uma das observações com maior influência negativa ao modelo.

\newpage

**Figura 17: DFBetas para as variáveis do modelo.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 4

ols_plot_dfbetas(mFit2)


showcases<-data.frame(dfbetas(mFit2))
showcases$ID<-rownames(showcases)

for (i in 1:45) {
  if (abs(showcases$ampat[i])>.3) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$avat[i])>.3) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$ampst[i])>.3) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$avst[i])>.3) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$amph[i])>.3) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$avh[i])>.3) {  
    discrepantes[i] <- discrepantes[i]+1
  }
  if (abs(showcases$wind[i])>.3) {  
    discrepantes[i] <- discrepantes[i]+1
  }
}
```

A Figura 17 apresenta os DFBetas para cada uma das variáveis utilizadas no modelo. Nota-se que as observações já identificadas como anômalas pelos gráficos anteriores se repetem com maior frequência na Figura 17.

\newpage

**Figura 18: DfFit para as variáveis do modelo.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

aaa <- ols_plot_dffits(mFit2)

for (i in 1:46) {
  if (!is.na(aaa[["data"]][["txt"]][i])) {  
    discrepantes[i] <- discrepantes[i]+1
  }  
}

```

A Figura 18 acompanha os gráficos anteriores apresentando mais uma vez a observação 38 como discrepante.

\newpage

**Figura 19: COVRatio para as variáveis do modelo.**

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 9

car::crPlots(mFit2)
```

Da Figura 19 verifica-se que as variáveis estão  diretamente correlacionadas com os resíduos da evaporação da água do solo, o que por sua vez indica que a inclusão de observações destas variáveis apresentam bom impacto ao modelo.


### Análise de Coliearidade dos Preditores

A colinearidade das variáveis preditoras pode ser avaliada por meio do cálculo dos **$R^2_j$** e $VIF_j$ destas variáveis, ver tabela 8.

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 9

aux <- colnames(dados2)
aux1 <- aux[-8]
R2_j <- NULL
VIF <- NULL
R2_j[1:7] <- 0
VIF[1:7] <- 0

for (k in 1:7){
  aux2 <- aux1[-k]
  j <- 1
  for (i in 1:7){
    if (i==k){
      colnames(dados2)[i] <- "aux1"
    }else{
      colnames(dados2)[i] <- paste("aux_",j, sep="")
      j <- j+1
    }
  }
  reg <- lm(aux1 ~ aux_1 + aux_2 + aux_3 + aux_4 + aux_5 + aux_6, data = dados2)
  R2_j[k] <- summary(reg)$r.squared
  VIF[k] <- 1/(1-R2_j[k])
}

colnames(dados2) <- aux
tab <- cbind(R2_j,VIF)
rownames(tab) <- c("Amplitude térmica do ar","Temperatura média do ar máxima",
                   "Amplitude térmica do solo","Temperatura média do solo",
                   "Amplitude da umidade relativa","Umidade relativa média",
                   "Vento total")

tab|>
  kbl(
    caption = "$R^2_j$ e VIF dos Preditores",
    digits = 3,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", row.names = T, booktabs = T
  )|>
  kable_material(c("striped", "hover", "condensed"))|>
  kable_styling(
    bootstrap_options = c("striped", "hover",  "condensed"),
    full_width = F,
    position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header")
  ) |>
  column_spec(1, bold = T)|>
  kable_material()
```

Uma regra empírica estabelece que valores de $VIF_j$ acima de dez implica em colinearidade entre as variáveis preditoras. Analisando a Tabela 8 observa-se que nenhuma das variáveis chegou proximo a esse valor, indicando, contrariamente ao senso comum, que não há uma colinearidade expressiva entre as variáveis preditoras.

### Eliminação de observações anômalas

Avaliando as observações que apresentaram comportamento anômalo nos diagnósticos dos valores ajustados e resíduos studentizados, valores ajustados e resíduos padronizados, distância de CooK, pontos de alavanca e *outliers*, análise de DfFit e todas as análises de BFBetas, chegamos as frequências de observações anômalas apresentadas na Figura 11.
```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

principais <- as.data.frame(cbind(1:46, discrepantes))
colnames(principais) <- c("Observação", "Ocorrências")

### Ajuste do Modelo + Gráfico ----
principais|>
  ggplot(aes(x = Observação, y = Ocorrências)) +
  geom_point(
    color = "#234B6E"
    )+
  labs(
    title = "Figura 20: Número de ocorrências para cada observação",
    y = 'Ocorrências',
    x = 'Observação'
  )+
  theme(legend.position = "none",
          axis.line = element_line(size = 0.5, color = "#222222"))


```

Considerando apenas as observações com 2 ou mais ocorrências temos a Tabela a seguir.

```{r }
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

principais <- principais %>% filter(discrepantes>1)

principais |>
  kableExtra::kbl(
    caption = "Observações com maior número de ocorrências.",
    align = c("l", "c"), 
    row.names = F, booktabs = T, escape = F
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position")
  )|>
   kable_material()

```
Podemos intuir que essas são as observações com maior impacto negativo no modelo. Logo, eliminando-as do conjunto de dados analizados, bem como as variáveis descritas como pouco relevantes pela Tabela 8, chegamos a um novo modelo dado por:


```{r }
#| echo: false
#| warning: false
dados2 <- dados2[-principais$Observação,]
n <- length(dados2$evap)
Y <- as.matrix(dados2$evap)
X <- as.matrix(dados2[,-c(4,6,7,8)])
X <- cbind(1,X)
betas <- (solve(t(X) %*% X)) %*% t(X) %*% Y
H = X %*% (solve(t(X) %*% X)) %*% t(X)
J <- matrix(1,n,n)
SQRes <- t(Y) %*% Y - t(betas) %*% t(X) %*% Y
SQReg <- t(betas) %*% t(X) %*% Y - (1/n)*t(Y) %*% J %*% Y
SQTot <- SQReg + SQRes

R2 <- round(SQReg/SQTot,3)
R2_aju <- round(1 - (SQRes/(n - 5))/(SQTot/(n -1)),3)
```


$Y_{i}^*=$`r round(betas[1],3)` `r round(betas[2],3)` $X_{1i}^*+$ `r round(betas[3],3)` $X_{2i}^* +$ `r round(betas[4],3)` $X_{3i}^*+$ `r round(betas[5],3)` $X_{4i}^*$ 


Onde:    
$Y_{i}^*$ - Evaporação do Solo;  
$X_{1i}^*$ - Amplitude térmica do ar;  
$X_{2i}^*$ - Temperatura do ar média;  
$X_{3i}^*$ - Amplitude térmica do solo;;  
$X_{4i}^*$ - Amplitude da umidade relativa.    



Neste novo modelo o coeficiente de determinação calculado foi de $R^2=$ `r R2`, o que denota que `r R2*100`% da variância dos dados é explicada pelo modelo. O valor deste novo coeficiente permite concluir que a eliminação das observações com maior impacto e das variáveis pouco relevantes ao modelo foi benéfica. Pode-se calcular o coeficiente de determinação ajustado igual a $R^2_a=$ `r R2_aju`



## Conclusões


Verificou-se que embora os dados apresentem assimetria e bom número de *outliers* foi possível propor um modelo de regressão linear múltipla para conhecer a quantidade de evaporação de água do solo.

O uso de amplitudes no lugar de mínimo e máximos pareceu eficiente para simplificar o modelo sem perda significativa de informação ao modelo de regressão linear multipla realizado. É de se supor ainda que essa transformação eliminou alguma colinearidade entre as variáveis preditoras.

As anomalias relatadas em cada um dos gráficos de diagnóstico elaborados foram tratadas de igual maneira contabilizando para cada observação o número de ocorrências observadas. Por este método se elencou as observações com maior potencial de prejuízo ao modelo e ao descartá-las do rol de dados avaliados obteve-se uma expressiva melhora no modelo.

O modelo final obtido, embora  mais simples que o inicial, foi capaz de ter um resultado expressivamente melhor confirmando a eficácia do uso das técnicas adotadas.
